{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeabaacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LOCAL'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress unnecessary Shapely warning\n",
    "warnings.filterwarnings('ignore',\n",
    "                        '.*Shapely GEOS version.*')\n",
    "\n",
    "from aiohttp import ClientSession\n",
    "from requests import request, Session\n",
    "from itertools import product, repeat\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from threading import Thread\n",
    "import time\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import shapely\n",
    "import pygeos\n",
    "from functools import reduce\n",
    "from pandas.plotting import lag_plot\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import copy\n",
    "import math\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from multiprocess import Process, Pool\n",
    "\n",
    "# Spark library\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col as spark_col\n",
    "\n",
    "# Using findspark ensures the spark path is\n",
    "# found and set, allowing us to use the\n",
    "# appropriate JAR files to connect to AWS\n",
    "import findspark\n",
    "location = findspark.find()\n",
    "findspark.init(location, edit_rc=True)\n",
    "\n",
    "# AWS library\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "\n",
    "\n",
    "# All helper functions are in this module:\n",
    "from helper_functions.census_functions import *\n",
    "\n",
    "# Set up Pandas defaults\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "# Connect to S3\n",
    "s3client = boto3.client(\"s3\")\n",
    "os.environ.setdefault(\"AWS_PROFILE\", \"default\")\n",
    "os.environ.setdefault(\"AWS_DEFAULT_REGION\", \"us-west-1\")\n",
    "\n",
    "# Set environment variables for LOCAL development ONLY!\n",
    "os.environ.setdefault(\"ENVIRON\", \"LOCAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37101a2b",
   "metadata": {},
   "source": [
    "## Get Census Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c2d08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census key: f25144e3809a49b45c5cc54e7d2bce532fe4ce99\n"
     ]
    }
   ],
   "source": [
    "# Test getting census key\n",
    "print(\"Census key:\", census_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30435e3",
   "metadata": {},
   "source": [
    "### Create the directories for file-saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5c0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(\"datasets/cleaned_census_api_files/\")\n",
    "create_folder(\"datasets/cleaned_census_api_files/graphable/\")\n",
    "create_folder(\"datasets/cleaned_census_api_files/raw/\")\n",
    "create_folder(\"datasets/cleaned_census_api_files/standardized/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d596b",
   "metadata": {},
   "source": [
    "## Following Tutorial Below\n",
    "Referencing [this](https://www.youtube.com/watch?v=LW-M_UC0VTE) tutorial.\n",
    "\n",
    "Here is the [Census API](https://www.census.gov/data/developers/data-sets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea3874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f65e2a0",
   "metadata": {},
   "source": [
    "## Get Block Group Level Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9446e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "start_year = 2013\n",
    "end_year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a37950",
   "metadata": {},
   "source": [
    "### Get Population by block group for 2013-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b707a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Start list\n",
    "df_list = []\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Start session\n",
    "session = Session()\n",
    "\n",
    "# Define our API variable\n",
    "# It's within a dictionary because some variables\n",
    "# can change names from year to year (but not all)\n",
    "census_code_dict = {\n",
    "    2013: 'B01003_001E',\n",
    "    2014: 'B01003_001E',\n",
    "    2015: 'B01003_001E', # No change in code number this year\n",
    "    2016: 'B01003_001E',\n",
    "    2017: 'B01003_001E',\n",
    "    2018: 'B01003_001E',\n",
    "    2019: 'B01003_001E',\n",
    "    2020: 'B01003_001E',\n",
    "    2021: 'B01003_001E'\n",
    "}\n",
    "\n",
    "census_code_meaning='population_blocks'\n",
    "\n",
    "# Run the API call\n",
    "asyncio.run(url_to_dataframe_async_owners(start_year, end_year, \n",
    "                                          fifty_states_list=fifty_states_list,\n",
    "                                          census_code_dict=census_code_dict,\n",
    "                                          df_list=df_list,\n",
    "                                          census_code_meaning=census_code_meaning,\n",
    "                                         get_blocks=True))\n",
    "\n",
    "# Get merged dataframe\n",
    "pop_by_blocks_raw = final_data_prep(df_list, census_code_meaning, blocks=True)\n",
    "pop_pre_st = merge_with_crosswalk(pop_by_blocks_raw)\n",
    "\n",
    "# Drop name and block group\n",
    "pop_pre_st.drop(columns=['name','block group'], inplace=True)\n",
    "\n",
    "# Save crosswalked file\n",
    "pop_pre_st.to_csv(\"datasets/cleaned_census_api_files/raw/merged_with_crosswalk/population_blocks_raw_crosswalked.csv\",\n",
    "                 index=False)\n",
    "\n",
    "### Save pop_pre_st to S3\n",
    "\n",
    "# Make block-group s3 path\n",
    "block_group_s3_path = \"s3://real-estate-wolff/census-data/block-groups/raw\"\n",
    "filename = \"population_blocks_raw.csv\"\n",
    "s3_path = f\"{block_group_s3_path}/{filename}\"\n",
    "\n",
    "# Save to s3\n",
    "wr.s3.to_csv(pop_pre_st, s3_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ad50e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://real-estate-wolff/census-data/block-groups/raw/population_blocks_raw.csv'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make block-group s3 path\n",
    "block_group_s3_path = \"s3://real-estate-wolff/census-data/block-groups/raw\"\n",
    "filename = \"population_blocks_raw.csv\"\n",
    "s3_path = f\"{block_group_s3_path}/{filename}\"\n",
    "\n",
    "# Save to s3\n",
    "wr.s3.to_csv(pop_pre_st, s3_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e03857a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>2013</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>BG10</th>\n",
       "      <th>BG20</th>\n",
       "      <th>wt_pop</th>\n",
       "      <th>wt_hu</th>\n",
       "      <th>wt_adult</th>\n",
       "      <th>wt_fam</th>\n",
       "      <th>wt_hh</th>\n",
       "      <th>parea</th>\n",
       "      <th>TRACT20</th>\n",
       "      <th>TRACT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500000US010010202001</td>\n",
       "      <td>1383.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1289.0000</td>\n",
       "      <td>1074.0000</td>\n",
       "      <td>960.0000</td>\n",
       "      <td>1020.0000</td>\n",
       "      <td>810.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>706.0000</td>\n",
       "      <td>844.0000</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561867</th>\n",
       "      <td>1500000US721537506012</td>\n",
       "      <td>3437.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>721537506012</td>\n",
       "      <td>2940.0000</td>\n",
       "      <td>2921.0000</td>\n",
       "      <td>2703.0000</td>\n",
       "      <td>2348.0000</td>\n",
       "      <td>2432.0000</td>\n",
       "      <td>2523.0000</td>\n",
       "      <td>1504.0000</td>\n",
       "      <td>1820.0000</td>\n",
       "      <td>721537506012</td>\n",
       "      <td>721537506013</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>72153750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561868</th>\n",
       "      <td>1500000US721537506013</td>\n",
       "      <td>1286.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>721537506013</td>\n",
       "      <td>1612.0000</td>\n",
       "      <td>1367.0000</td>\n",
       "      <td>1195.0000</td>\n",
       "      <td>1292.0000</td>\n",
       "      <td>976.0000</td>\n",
       "      <td>991.0000</td>\n",
       "      <td>1276.0000</td>\n",
       "      <td>1213.0000</td>\n",
       "      <td>721537506013</td>\n",
       "      <td>721537506011</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>72153750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561869</th>\n",
       "      <td>1500000US721537506021</td>\n",
       "      <td>2332.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>721537506021</td>\n",
       "      <td>2351.0000</td>\n",
       "      <td>1994.0000</td>\n",
       "      <td>2005.0000</td>\n",
       "      <td>2055.0000</td>\n",
       "      <td>1707.0000</td>\n",
       "      <td>1577.0000</td>\n",
       "      <td>1410.0000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>721537506021</td>\n",
       "      <td>721537506021</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561870</th>\n",
       "      <td>1500000US721537506022</td>\n",
       "      <td>856.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>916.0000</td>\n",
       "      <td>747.0000</td>\n",
       "      <td>736.0000</td>\n",
       "      <td>946.0000</td>\n",
       "      <td>804.0000</td>\n",
       "      <td>648.0000</td>\n",
       "      <td>801.0000</td>\n",
       "      <td>894.0000</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561871</th>\n",
       "      <td>1500000US721537506022</td>\n",
       "      <td>856.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>916.0000</td>\n",
       "      <td>747.0000</td>\n",
       "      <td>736.0000</td>\n",
       "      <td>946.0000</td>\n",
       "      <td>804.0000</td>\n",
       "      <td>648.0000</td>\n",
       "      <td>801.0000</td>\n",
       "      <td>894.0000</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561872 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       geo_id      2013 state county        tract  \\\n",
       "0       1500000US010010201001  637.0000    01    001  01001020100   \n",
       "1       1500000US010010201001  637.0000    01    001  01001020100   \n",
       "2       1500000US010010201002 1171.0000    01    001  01001020100   \n",
       "3       1500000US010010201002 1171.0000    01    001  01001020100   \n",
       "4       1500000US010010202001 1383.0000    01    001  01001020200   \n",
       "...                       ...       ...   ...    ...          ...   \n",
       "561867  1500000US721537506012 3437.0000    72    153  72153750601   \n",
       "561868  1500000US721537506013 1286.0000    72    153  72153750601   \n",
       "561869  1500000US721537506021 2332.0000    72    153  72153750602   \n",
       "561870  1500000US721537506022  856.0000    72    153  72153750602   \n",
       "561871  1500000US721537506022  856.0000    72    153  72153750602   \n",
       "\n",
       "               block      2014      2015      2016      2017      2018  \\\n",
       "0       010010201001  676.0000  649.0000  745.0000  692.0000  636.0000   \n",
       "1       010010201001  676.0000  649.0000  745.0000  692.0000  636.0000   \n",
       "2       010010201002 1224.0000 1299.0000 1265.0000 1153.0000 1287.0000   \n",
       "3       010010201002 1224.0000 1299.0000 1265.0000 1153.0000 1287.0000   \n",
       "4       010010202001 1289.0000 1074.0000  960.0000 1020.0000  810.0000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "561867  721537506012 2940.0000 2921.0000 2703.0000 2348.0000 2432.0000   \n",
       "561868  721537506013 1612.0000 1367.0000 1195.0000 1292.0000  976.0000   \n",
       "561869  721537506021 2351.0000 1994.0000 2005.0000 2055.0000 1707.0000   \n",
       "561870  721537506022  916.0000  747.0000  736.0000  946.0000  804.0000   \n",
       "561871  721537506022  916.0000  747.0000  736.0000  946.0000  804.0000   \n",
       "\n",
       "            2019      2020      2021          BG10          BG20  wt_pop  \\\n",
       "0       730.0000  674.0000  693.0000  010010201001  010010201001  1.0000   \n",
       "1       730.0000  674.0000  693.0000  010010201001  010010201001  1.0000   \n",
       "2      1263.0000 1267.0000 1098.0000  010010201002  010010201002  1.0000   \n",
       "3      1263.0000 1267.0000 1098.0000  010010201002  010010208031  0.0000   \n",
       "4       835.0000  706.0000  844.0000  010010202001  010010202001  1.0000   \n",
       "...          ...       ...       ...           ...           ...     ...   \n",
       "561867 2523.0000 1504.0000 1820.0000  721537506012  721537506013  0.6173   \n",
       "561868  991.0000 1276.0000 1213.0000  721537506013  721537506011  1.0000   \n",
       "561869 1577.0000 1410.0000 1295.0000  721537506021  721537506021  1.0000   \n",
       "561870  648.0000  801.0000  894.0000  721537506022  721537506022  1.0000   \n",
       "561871  648.0000  801.0000  894.0000  721537506022  721537506022  1.0000   \n",
       "\n",
       "        wt_hu  wt_adult  wt_fam  wt_hh  parea      TRACT20      TRACT10  \n",
       "0      1.0000    1.0000  1.0000 1.0000 1.0000  01001020100  01001020100  \n",
       "1      1.0000    1.0000  1.0000 1.0000 1.0000  01001020100  01001020100  \n",
       "2      1.0000    1.0000  1.0000 1.0000 0.9988  01001020100  01001020100  \n",
       "3      0.0000    0.0000  0.0000 0.0000 0.0012  01001020803  01001020100  \n",
       "4      1.0000    1.0000  1.0000 1.0000 1.0000  01001020200  01001020200  \n",
       "...       ...       ...     ...    ...    ...          ...          ...  \n",
       "561867 0.6167    0.6037  0.6202 0.6077 0.8305  72153750601  72153750601  \n",
       "561868 1.0000    1.0000  1.0000 1.0000 1.0000  72153750601  72153750601  \n",
       "561869 1.0000    1.0000  1.0000 1.0000 1.0000  72153750602  72153750602  \n",
       "561870 1.0000    1.0000  1.0000 1.0000 1.0000  72153750602  72153750602  \n",
       "561871 1.0000    1.0000  1.0000 1.0000 1.0000  72153750602  72153750602  \n",
       "\n",
       "[561872 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataframe\n",
    "pop_pre_st = pd.read_csv(\n",
    "    \"datasets/cleaned_census_api_files/raw/merged_with_crosswalk/population_blocks_raw_crosswalked.csv\",\n",
    "    encoding='utf-8',\n",
    "    dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "          'tract':str, 'block':str, 'BG10':str, 'BG20':str,\n",
    "          'TRACT20':str, 'TRACT10':str})\n",
    "pop_pre_st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac0394",
   "metadata": {},
   "source": [
    "#### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7843515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This can and should be assigned to cloud parrallelization.\n",
    "# The good thing is this function only needs to run once.\n",
    "year_end = 2021\n",
    "pop_dictionary = {}\n",
    "array2 = pop_pre_st['BG20'].unique()\n",
    "\n",
    "# Run the standardization function\n",
    "[block_standardize(\n",
    "    x, pop_dict=pop_dictionary, og_df=pop_pre_st, year_end=year_end) for x in array2]\n",
    "\n",
    "saved_pop_dictionary = pop_dictionary.copy()\n",
    "\n",
    "pop_standardized_df_1 = (pd.DataFrame.from_dict(saved_pop_dictionary, \n",
    "                       orient='index', \n",
    "                       columns=[str(i) for i in range(2013, year_end + 1)])\n",
    "                       .reset_index()\n",
    "                       .rename(columns={'index':'geoid_block'})\n",
    "                      )\n",
    "\n",
    "pop_standardized_df_1.to_csv('datasets/cleaned_census_api_files/raw/population_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6f9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47023761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>name</th>\n",
       "      <th>2013</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block group</th>\n",
       "      <th>block</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>BG10</th>\n",
       "      <th>BG20</th>\n",
       "      <th>wt_pop</th>\n",
       "      <th>wt_hu</th>\n",
       "      <th>wt_adult</th>\n",
       "      <th>wt_fam</th>\n",
       "      <th>wt_hh</th>\n",
       "      <th>parea</th>\n",
       "      <th>TRACT20</th>\n",
       "      <th>TRACT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>Block Group 1, Census Tract 201, Autauga Count...</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  geo_id                                               name  \\\n",
       "0  1500000US010010201001  Block Group 1, Census Tract 201, Autauga Count...   \n",
       "\n",
       "      2013 state county        tract block group         block     2014  \\\n",
       "0 637.0000    01    001  01001020100           1  010010201001 676.0000   \n",
       "\n",
       "      2015     2016     2017     2018     2019     2020     2021  \\\n",
       "0 649.0000 745.0000 692.0000 636.0000 730.0000 674.0000 693.0000   \n",
       "\n",
       "           BG10          BG20  wt_pop  wt_hu  wt_adult  wt_fam  wt_hh  parea  \\\n",
       "0  010010201001  010010201001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "\n",
       "       TRACT20      TRACT10  \n",
       "0  01001020100  01001020100  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_pre_st.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d57b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>name</th>\n",
       "      <th>2013</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block group</th>\n",
       "      <th>block</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>BG10</th>\n",
       "      <th>BG20</th>\n",
       "      <th>wt_pop</th>\n",
       "      <th>wt_hu</th>\n",
       "      <th>wt_adult</th>\n",
       "      <th>wt_fam</th>\n",
       "      <th>wt_hh</th>\n",
       "      <th>parea</th>\n",
       "      <th>TRACT20</th>\n",
       "      <th>TRACT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>Block Group 1, Census Tract 201, Autauga Count...</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>Block Group 1, Census Tract 201, Autauga Count...</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>1</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>Block Group 2, Census Tract 201, Autauga Count...</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>2</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>Block Group 2, Census Tract 201, Autauga Count...</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>2</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500000US010010202001</td>\n",
       "      <td>Block Group 1, Census Tract 202, Autauga Count...</td>\n",
       "      <td>1383.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>1</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1289.0000</td>\n",
       "      <td>1074.0000</td>\n",
       "      <td>960.0000</td>\n",
       "      <td>1020.0000</td>\n",
       "      <td>810.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>706.0000</td>\n",
       "      <td>844.0000</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1500000US010010202002</td>\n",
       "      <td>Block Group 2, Census Tract 202, Autauga Count...</td>\n",
       "      <td>972.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>2</td>\n",
       "      <td>010010202002</td>\n",
       "      <td>1053.0000</td>\n",
       "      <td>1082.0000</td>\n",
       "      <td>1236.0000</td>\n",
       "      <td>1152.0000</td>\n",
       "      <td>1218.0000</td>\n",
       "      <td>1124.0000</td>\n",
       "      <td>1051.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>010010202002</td>\n",
       "      <td>010010202002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1500000US010010202002</td>\n",
       "      <td>Block Group 2, Census Tract 202, Autauga Count...</td>\n",
       "      <td>972.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>2</td>\n",
       "      <td>010010202002</td>\n",
       "      <td>1053.0000</td>\n",
       "      <td>1082.0000</td>\n",
       "      <td>1236.0000</td>\n",
       "      <td>1152.0000</td>\n",
       "      <td>1218.0000</td>\n",
       "      <td>1124.0000</td>\n",
       "      <td>1051.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>010010202002</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1500000US010010203001</td>\n",
       "      <td>Block Group 1, Census Tract 203, Autauga Count...</td>\n",
       "      <td>2366.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>1</td>\n",
       "      <td>010010203001</td>\n",
       "      <td>2376.0000</td>\n",
       "      <td>2143.0000</td>\n",
       "      <td>2364.0000</td>\n",
       "      <td>2555.0000</td>\n",
       "      <td>2641.0000</td>\n",
       "      <td>2774.0000</td>\n",
       "      <td>2912.0000</td>\n",
       "      <td>2685.0000</td>\n",
       "      <td>010010203001</td>\n",
       "      <td>010010203001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>01001020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1500000US010010203002</td>\n",
       "      <td>Block Group 2, Census Tract 203, Autauga Count...</td>\n",
       "      <td>691.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>2</td>\n",
       "      <td>010010203002</td>\n",
       "      <td>921.0000</td>\n",
       "      <td>825.0000</td>\n",
       "      <td>772.0000</td>\n",
       "      <td>830.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>733.0000</td>\n",
       "      <td>782.0000</td>\n",
       "      <td>892.0000</td>\n",
       "      <td>010010203002</td>\n",
       "      <td>010010203002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>01001020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1500000US010010204001</td>\n",
       "      <td>Block Group 1, Census Tract 204, Autauga Count...</td>\n",
       "      <td>1088.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>1</td>\n",
       "      <td>010010204001</td>\n",
       "      <td>970.0000</td>\n",
       "      <td>785.0000</td>\n",
       "      <td>729.0000</td>\n",
       "      <td>651.0000</td>\n",
       "      <td>653.0000</td>\n",
       "      <td>761.0000</td>\n",
       "      <td>720.0000</td>\n",
       "      <td>733.0000</td>\n",
       "      <td>010010204001</td>\n",
       "      <td>010010204001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>01001020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1500000US010010204002</td>\n",
       "      <td>Block Group 2, Census Tract 204, Autauga Count...</td>\n",
       "      <td>1895.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>2</td>\n",
       "      <td>010010204002</td>\n",
       "      <td>1884.0000</td>\n",
       "      <td>2228.0000</td>\n",
       "      <td>2303.0000</td>\n",
       "      <td>2217.0000</td>\n",
       "      <td>1903.0000</td>\n",
       "      <td>1756.0000</td>\n",
       "      <td>1713.0000</td>\n",
       "      <td>1655.0000</td>\n",
       "      <td>010010204002</td>\n",
       "      <td>010010204002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>01001020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1500000US010010204003</td>\n",
       "      <td>Block Group 3, Census Tract 204, Autauga Count...</td>\n",
       "      <td>966.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>3</td>\n",
       "      <td>010010204003</td>\n",
       "      <td>949.0000</td>\n",
       "      <td>909.0000</td>\n",
       "      <td>978.0000</td>\n",
       "      <td>813.0000</td>\n",
       "      <td>705.0000</td>\n",
       "      <td>866.0000</td>\n",
       "      <td>707.0000</td>\n",
       "      <td>742.0000</td>\n",
       "      <td>010010204003</td>\n",
       "      <td>010010204003</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>01001020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1500000US010010204004</td>\n",
       "      <td>Block Group 4, Census Tract 204, Autauga Count...</td>\n",
       "      <td>454.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>4</td>\n",
       "      <td>010010204004</td>\n",
       "      <td>469.0000</td>\n",
       "      <td>501.0000</td>\n",
       "      <td>553.0000</td>\n",
       "      <td>586.0000</td>\n",
       "      <td>570.0000</td>\n",
       "      <td>495.0000</td>\n",
       "      <td>399.0000</td>\n",
       "      <td>672.0000</td>\n",
       "      <td>010010204004</td>\n",
       "      <td>010010204004</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>01001020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1500000US010010205001</td>\n",
       "      <td>Block Group 1, Census Tract 205, Autauga Count...</td>\n",
       "      <td>1859.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>1</td>\n",
       "      <td>010010205001</td>\n",
       "      <td>1961.0000</td>\n",
       "      <td>1936.0000</td>\n",
       "      <td>1947.0000</td>\n",
       "      <td>2068.0000</td>\n",
       "      <td>2150.0000</td>\n",
       "      <td>1972.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205001</td>\n",
       "      <td>010010205011</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500000US010010205002</td>\n",
       "      <td>Block Group 2, Census Tract 205, Autauga Count...</td>\n",
       "      <td>7001.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>2</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>6993.0000</td>\n",
       "      <td>7232.0000</td>\n",
       "      <td>7250.0000</td>\n",
       "      <td>6130.0000</td>\n",
       "      <td>6013.0000</td>\n",
       "      <td>6015.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205031</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1500000US010010205002</td>\n",
       "      <td>Block Group 2, Census Tract 205, Autauga Count...</td>\n",
       "      <td>7001.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>2</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>6993.0000</td>\n",
       "      <td>7232.0000</td>\n",
       "      <td>7250.0000</td>\n",
       "      <td>6130.0000</td>\n",
       "      <td>6013.0000</td>\n",
       "      <td>6015.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205021</td>\n",
       "      <td>0.2966</td>\n",
       "      <td>0.2887</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.2863</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>01001020502</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1500000US010010205002</td>\n",
       "      <td>Block Group 2, Census Tract 205, Autauga Count...</td>\n",
       "      <td>7001.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>2</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>6993.0000</td>\n",
       "      <td>7232.0000</td>\n",
       "      <td>7250.0000</td>\n",
       "      <td>6130.0000</td>\n",
       "      <td>6013.0000</td>\n",
       "      <td>6015.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205022</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>01001020502</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1500000US010010205002</td>\n",
       "      <td>Block Group 2, Census Tract 205, Autauga Count...</td>\n",
       "      <td>7001.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>2</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>6993.0000</td>\n",
       "      <td>7232.0000</td>\n",
       "      <td>7250.0000</td>\n",
       "      <td>6130.0000</td>\n",
       "      <td>6013.0000</td>\n",
       "      <td>6015.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205032</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1500000US010010205002</td>\n",
       "      <td>Block Group 2, Census Tract 205, Autauga Count...</td>\n",
       "      <td>7001.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>2</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>6993.0000</td>\n",
       "      <td>7232.0000</td>\n",
       "      <td>7250.0000</td>\n",
       "      <td>6130.0000</td>\n",
       "      <td>6013.0000</td>\n",
       "      <td>6015.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205033</td>\n",
       "      <td>0.2368</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1500000US010010205003</td>\n",
       "      <td>Block Group 3, Census Tract 205, Autauga Count...</td>\n",
       "      <td>1991.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>3</td>\n",
       "      <td>010010205003</td>\n",
       "      <td>1927.0000</td>\n",
       "      <td>1595.0000</td>\n",
       "      <td>1332.0000</td>\n",
       "      <td>1767.0000</td>\n",
       "      <td>1720.0000</td>\n",
       "      <td>2609.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205003</td>\n",
       "      <td>010010205012</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1500000US010010205011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0000</td>\n",
       "      <td>1847.0000</td>\n",
       "      <td>010010205001</td>\n",
       "      <td>010010205011</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1500000US010010205012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2300.0000</td>\n",
       "      <td>2534.0000</td>\n",
       "      <td>010010205003</td>\n",
       "      <td>010010205012</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020501</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1500000US010010205021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1951.0000</td>\n",
       "      <td>1808.0000</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205021</td>\n",
       "      <td>0.2966</td>\n",
       "      <td>0.2887</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.2863</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>01001020502</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1500000US010010205022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1149.0000</td>\n",
       "      <td>1520.0000</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205022</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>0.1893</td>\n",
       "      <td>01001020502</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1500000US010010205031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891.0000</td>\n",
       "      <td>899.0000</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205031</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1500000US010010205032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>885.0000</td>\n",
       "      <td>903.0000</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205032</td>\n",
       "      <td>0.1969</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1500000US010010205033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010205033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1492.0000</td>\n",
       "      <td>1372.0000</td>\n",
       "      <td>010010205002</td>\n",
       "      <td>010010205033</td>\n",
       "      <td>0.2368</td>\n",
       "      <td>0.2158</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>01001020503</td>\n",
       "      <td>01001020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1500000US010010206001</td>\n",
       "      <td>Block Group 1, Census Tract 206, Autauga Count...</td>\n",
       "      <td>2608.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>1</td>\n",
       "      <td>010010206001</td>\n",
       "      <td>2950.0000</td>\n",
       "      <td>3157.0000</td>\n",
       "      <td>3030.0000</td>\n",
       "      <td>2710.0000</td>\n",
       "      <td>2555.0000</td>\n",
       "      <td>2550.0000</td>\n",
       "      <td>1052.0000</td>\n",
       "      <td>1277.0000</td>\n",
       "      <td>010010206001</td>\n",
       "      <td>010010206003</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>01001020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1500000US010010206001</td>\n",
       "      <td>Block Group 1, Census Tract 206, Autauga Count...</td>\n",
       "      <td>2608.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>1</td>\n",
       "      <td>010010206001</td>\n",
       "      <td>2950.0000</td>\n",
       "      <td>3157.0000</td>\n",
       "      <td>3030.0000</td>\n",
       "      <td>2710.0000</td>\n",
       "      <td>2555.0000</td>\n",
       "      <td>2550.0000</td>\n",
       "      <td>1052.0000</td>\n",
       "      <td>1277.0000</td>\n",
       "      <td>010010206001</td>\n",
       "      <td>010010206002</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.2982</td>\n",
       "      <td>0.2774</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.2973</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>01001020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1500000US010010206003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010206003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1840.0000</td>\n",
       "      <td>1991.0000</td>\n",
       "      <td>010010206001</td>\n",
       "      <td>010010206003</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.7027</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>01001020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1500000US010010208021</td>\n",
       "      <td>Block Group 1, Census Tract 208.02, Autauga Co...</td>\n",
       "      <td>2535.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020802</td>\n",
       "      <td>1</td>\n",
       "      <td>010010208021</td>\n",
       "      <td>2495.0000</td>\n",
       "      <td>2677.0000</td>\n",
       "      <td>2949.0000</td>\n",
       "      <td>3239.0000</td>\n",
       "      <td>3099.0000</td>\n",
       "      <td>3158.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010208021</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1500000US010010208031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>811.0000</td>\n",
       "      <td>1248.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1500000US010010208031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>811.0000</td>\n",
       "      <td>1248.0000</td>\n",
       "      <td>010010208021</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.2882</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geo_id                                               name  \\\n",
       "0   1500000US010010201001  Block Group 1, Census Tract 201, Autauga Count...   \n",
       "1   1500000US010010201001  Block Group 1, Census Tract 201, Autauga Count...   \n",
       "2   1500000US010010201002  Block Group 2, Census Tract 201, Autauga Count...   \n",
       "3   1500000US010010201002  Block Group 2, Census Tract 201, Autauga Count...   \n",
       "4   1500000US010010202001  Block Group 1, Census Tract 202, Autauga Count...   \n",
       "5   1500000US010010202002  Block Group 2, Census Tract 202, Autauga Count...   \n",
       "6   1500000US010010202002  Block Group 2, Census Tract 202, Autauga Count...   \n",
       "7   1500000US010010203001  Block Group 1, Census Tract 203, Autauga Count...   \n",
       "8   1500000US010010203002  Block Group 2, Census Tract 203, Autauga Count...   \n",
       "9   1500000US010010204001  Block Group 1, Census Tract 204, Autauga Count...   \n",
       "10  1500000US010010204002  Block Group 2, Census Tract 204, Autauga Count...   \n",
       "11  1500000US010010204003  Block Group 3, Census Tract 204, Autauga Count...   \n",
       "12  1500000US010010204004  Block Group 4, Census Tract 204, Autauga Count...   \n",
       "13  1500000US010010205001  Block Group 1, Census Tract 205, Autauga Count...   \n",
       "14  1500000US010010205002  Block Group 2, Census Tract 205, Autauga Count...   \n",
       "15  1500000US010010205002  Block Group 2, Census Tract 205, Autauga Count...   \n",
       "16  1500000US010010205002  Block Group 2, Census Tract 205, Autauga Count...   \n",
       "17  1500000US010010205002  Block Group 2, Census Tract 205, Autauga Count...   \n",
       "18  1500000US010010205002  Block Group 2, Census Tract 205, Autauga Count...   \n",
       "19  1500000US010010205003  Block Group 3, Census Tract 205, Autauga Count...   \n",
       "20  1500000US010010205011                                                NaN   \n",
       "21  1500000US010010205012                                                NaN   \n",
       "22  1500000US010010205021                                                NaN   \n",
       "23  1500000US010010205022                                                NaN   \n",
       "24  1500000US010010205031                                                NaN   \n",
       "25  1500000US010010205032                                                NaN   \n",
       "26  1500000US010010205033                                                NaN   \n",
       "27  1500000US010010206001  Block Group 1, Census Tract 206, Autauga Count...   \n",
       "28  1500000US010010206001  Block Group 1, Census Tract 206, Autauga Count...   \n",
       "30  1500000US010010206003                                                NaN   \n",
       "39  1500000US010010208021  Block Group 1, Census Tract 208.02, Autauga Co...   \n",
       "47  1500000US010010208031                                                NaN   \n",
       "48  1500000US010010208031                                                NaN   \n",
       "\n",
       "        2013 state county        tract block group         block      2014  \\\n",
       "0   637.0000    01    001  01001020100           1  010010201001  676.0000   \n",
       "1   637.0000    01    001  01001020100           1  010010201001  676.0000   \n",
       "2  1171.0000    01    001  01001020100           2  010010201002 1224.0000   \n",
       "3  1171.0000    01    001  01001020100           2  010010201002 1224.0000   \n",
       "4  1383.0000    01    001  01001020200           1  010010202001 1289.0000   \n",
       "5   972.0000    01    001  01001020200           2  010010202002 1053.0000   \n",
       "6   972.0000    01    001  01001020200           2  010010202002 1053.0000   \n",
       "7  2366.0000    01    001  01001020300           1  010010203001 2376.0000   \n",
       "8   691.0000    01    001  01001020300           2  010010203002  921.0000   \n",
       "9  1088.0000    01    001  01001020400           1  010010204001  970.0000   \n",
       "10 1895.0000    01    001  01001020400           2  010010204002 1884.0000   \n",
       "11  966.0000    01    001  01001020400           3  010010204003  949.0000   \n",
       "12  454.0000    01    001  01001020400           4  010010204004  469.0000   \n",
       "13 1859.0000    01    001  01001020500           1  010010205001 1961.0000   \n",
       "14 7001.0000    01    001  01001020500           2  010010205002 6993.0000   \n",
       "15 7001.0000    01    001  01001020500           2  010010205002 6993.0000   \n",
       "16 7001.0000    01    001  01001020500           2  010010205002 6993.0000   \n",
       "17 7001.0000    01    001  01001020500           2  010010205002 6993.0000   \n",
       "18 7001.0000    01    001  01001020500           2  010010205002 6993.0000   \n",
       "19 1991.0000    01    001  01001020500           3  010010205003 1927.0000   \n",
       "20       NaN    01    001  01001020501         NaN  010010205011       NaN   \n",
       "21       NaN    01    001  01001020501         NaN  010010205012       NaN   \n",
       "22       NaN    01    001  01001020502         NaN  010010205021       NaN   \n",
       "23       NaN    01    001  01001020502         NaN  010010205022       NaN   \n",
       "24       NaN    01    001  01001020503         NaN  010010205031       NaN   \n",
       "25       NaN    01    001  01001020503         NaN  010010205032       NaN   \n",
       "26       NaN    01    001  01001020503         NaN  010010205033       NaN   \n",
       "27 2608.0000    01    001  01001020600           1  010010206001 2950.0000   \n",
       "28 2608.0000    01    001  01001020600           1  010010206001 2950.0000   \n",
       "30       NaN    01    001  01001020600         NaN  010010206003       NaN   \n",
       "39 2535.0000    01    001  01001020802           1  010010208021 2495.0000   \n",
       "47       NaN    01    001  01001020803         NaN  010010208031       NaN   \n",
       "48       NaN    01    001  01001020803         NaN  010010208031       NaN   \n",
       "\n",
       "        2015      2016      2017      2018      2019      2020      2021  \\\n",
       "0   649.0000  745.0000  692.0000  636.0000  730.0000  674.0000  693.0000   \n",
       "1   649.0000  745.0000  692.0000  636.0000  730.0000  674.0000  693.0000   \n",
       "2  1299.0000 1265.0000 1153.0000 1287.0000 1263.0000 1267.0000 1098.0000   \n",
       "3  1299.0000 1265.0000 1153.0000 1287.0000 1263.0000 1267.0000 1098.0000   \n",
       "4  1074.0000  960.0000 1020.0000  810.0000  835.0000  706.0000  844.0000   \n",
       "5  1082.0000 1236.0000 1152.0000 1218.0000 1124.0000 1051.0000 1166.0000   \n",
       "6  1082.0000 1236.0000 1152.0000 1218.0000 1124.0000 1051.0000 1166.0000   \n",
       "7  2143.0000 2364.0000 2555.0000 2641.0000 2774.0000 2912.0000 2685.0000   \n",
       "8   825.0000  772.0000  830.0000  835.0000  733.0000  782.0000  892.0000   \n",
       "9   785.0000  729.0000  651.0000  653.0000  761.0000  720.0000  733.0000   \n",
       "10 2228.0000 2303.0000 2217.0000 1903.0000 1756.0000 1713.0000 1655.0000   \n",
       "11  909.0000  978.0000  813.0000  705.0000  866.0000  707.0000  742.0000   \n",
       "12  501.0000  553.0000  586.0000  570.0000  495.0000  399.0000  672.0000   \n",
       "13 1936.0000 1947.0000 2068.0000 2150.0000 1972.0000       NaN       NaN   \n",
       "14 7232.0000 7250.0000 6130.0000 6013.0000 6015.0000       NaN       NaN   \n",
       "15 7232.0000 7250.0000 6130.0000 6013.0000 6015.0000       NaN       NaN   \n",
       "16 7232.0000 7250.0000 6130.0000 6013.0000 6015.0000       NaN       NaN   \n",
       "17 7232.0000 7250.0000 6130.0000 6013.0000 6015.0000       NaN       NaN   \n",
       "18 7232.0000 7250.0000 6130.0000 6013.0000 6015.0000       NaN       NaN   \n",
       "19 1595.0000 1332.0000 1767.0000 1720.0000 2609.0000       NaN       NaN   \n",
       "20       NaN       NaN       NaN       NaN       NaN 2006.0000 1847.0000   \n",
       "21       NaN       NaN       NaN       NaN       NaN 2300.0000 2534.0000   \n",
       "22       NaN       NaN       NaN       NaN       NaN 1951.0000 1808.0000   \n",
       "23       NaN       NaN       NaN       NaN       NaN 1149.0000 1520.0000   \n",
       "24       NaN       NaN       NaN       NaN       NaN  891.0000  899.0000   \n",
       "25       NaN       NaN       NaN       NaN       NaN  885.0000  903.0000   \n",
       "26       NaN       NaN       NaN       NaN       NaN 1492.0000 1372.0000   \n",
       "27 3157.0000 3030.0000 2710.0000 2555.0000 2550.0000 1052.0000 1277.0000   \n",
       "28 3157.0000 3030.0000 2710.0000 2555.0000 2550.0000 1052.0000 1277.0000   \n",
       "30       NaN       NaN       NaN       NaN       NaN 1840.0000 1991.0000   \n",
       "39 2677.0000 2949.0000 3239.0000 3099.0000 3158.0000       NaN       NaN   \n",
       "47       NaN       NaN       NaN       NaN       NaN  811.0000 1248.0000   \n",
       "48       NaN       NaN       NaN       NaN       NaN  811.0000 1248.0000   \n",
       "\n",
       "            BG10          BG20  wt_pop  wt_hu  wt_adult  wt_fam  wt_hh  parea  \\\n",
       "0   010010201001  010010201001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "1   010010201001  010010201001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "2   010010201002  010010201002  1.0000 1.0000    1.0000  1.0000 1.0000 0.9988   \n",
       "3   010010201002  010010208031  0.0000 0.0000    0.0000  0.0000 0.0000 0.0012   \n",
       "4   010010202001  010010202001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "5   010010202002  010010202002  1.0000 1.0000    1.0000  1.0000 1.0000 0.9962   \n",
       "6   010010202002  010010201001  0.0000 0.0000    0.0000  0.0000 0.0000 0.0038   \n",
       "7   010010203001  010010203001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "8   010010203002  010010203002  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "9   010010204001  010010204001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "10  010010204002  010010204002  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "11  010010204003  010010204003  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "12  010010204004  010010204004  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "13  010010205001  010010205011  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "14  010010205002  010010205031  0.0857 0.1004    0.0891  0.0764 0.0996 0.1249   \n",
       "15  010010205002  010010205021  0.2966 0.2887    0.2791  0.2998 0.2863 0.2137   \n",
       "16  010010205002  010010205022  0.1840 0.1981    0.1901  0.1935 0.1982 0.1893   \n",
       "17  010010205002  010010205032  0.1969 0.1970    0.2115  0.1825 0.1966 0.2206   \n",
       "18  010010205002  010010205033  0.2368 0.2158    0.2302  0.2477 0.2194 0.2516   \n",
       "19  010010205003  010010205012  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "20  010010205001  010010205011  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "21  010010205003  010010205012  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "22  010010205002  010010205021  0.2966 0.2887    0.2791  0.2998 0.2863 0.2137   \n",
       "23  010010205002  010010205022  0.1840 0.1981    0.1901  0.1935 0.1982 0.1893   \n",
       "24  010010205002  010010205031  0.0857 0.1004    0.0891  0.0764 0.0996 0.1249   \n",
       "25  010010205002  010010205032  0.1969 0.1970    0.2115  0.1825 0.1966 0.2206   \n",
       "26  010010205002  010010205033  0.2368 0.2158    0.2302  0.2477 0.2194 0.2516   \n",
       "27  010010206001  010010206003  0.7260 0.7018    0.7226  0.7331 0.7027 0.8020   \n",
       "28  010010206001  010010206002  0.2740 0.2982    0.2774  0.2669 0.2973 0.1980   \n",
       "30  010010206001  010010206003  0.7260 0.7018    0.7226  0.7331 0.7027 0.8020   \n",
       "39  010010208021  010010208031  0.2879 0.2694    0.2882  0.2964 0.2798 0.2506   \n",
       "47  010010201002  010010208031  0.0000 0.0000    0.0000  0.0000 0.0000 0.0012   \n",
       "48  010010208021  010010208031  0.2879 0.2694    0.2882  0.2964 0.2798 0.2506   \n",
       "\n",
       "        TRACT20      TRACT10  \n",
       "0   01001020100  01001020100  \n",
       "1   01001020100  01001020100  \n",
       "2   01001020100  01001020100  \n",
       "3   01001020803  01001020100  \n",
       "4   01001020200  01001020200  \n",
       "5   01001020200  01001020200  \n",
       "6   01001020100  01001020200  \n",
       "7   01001020300  01001020300  \n",
       "8   01001020300  01001020300  \n",
       "9   01001020400  01001020400  \n",
       "10  01001020400  01001020400  \n",
       "11  01001020400  01001020400  \n",
       "12  01001020400  01001020400  \n",
       "13  01001020501  01001020500  \n",
       "14  01001020503  01001020500  \n",
       "15  01001020502  01001020500  \n",
       "16  01001020502  01001020500  \n",
       "17  01001020503  01001020500  \n",
       "18  01001020503  01001020500  \n",
       "19  01001020501  01001020500  \n",
       "20  01001020501  01001020500  \n",
       "21  01001020501  01001020500  \n",
       "22  01001020502  01001020500  \n",
       "23  01001020502  01001020500  \n",
       "24  01001020503  01001020500  \n",
       "25  01001020503  01001020500  \n",
       "26  01001020503  01001020500  \n",
       "27  01001020600  01001020600  \n",
       "28  01001020600  01001020600  \n",
       "30  01001020600  01001020600  \n",
       "39  01001020803  01001020802  \n",
       "47  01001020803  01001020100  \n",
       "48  01001020803  01001020802  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_pre_st[\n",
    "    pop_pre_st['BG20'].isin(\n",
    "        pop_pre_st['BG20'].unique()[:20])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeac974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab609a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_standardize_tuple(tuple):\n",
    "    \"\"\"\n",
    "    WARNING: This function alone takes a few seconds to complete\n",
    "    per block group, but to standard all 242,333 block groups\n",
    "    can take many, many hours to run.\n",
    "    It would be wise to run this function on any type of\n",
    "    parrallel processing, such as using Dask, or a GPU,\n",
    "    or parrallelized cloud computing, as there is no\n",
    "    serialization (the block groups can be standardized\n",
    "    in no particular order).\n",
    "    \n",
    "    This function standardizes all block group rows. It \n",
    "    should be called in a loop or vectorized if possible,\n",
    "    such as the example below. (Note, the example below\n",
    "    may not be the most efficient way to loop through\n",
    "    or vectorize the block groups.)\n",
    "    \n",
    "    ```\n",
    "    # Loop through all population block groups\n",
    "    # and standardize them\n",
    "    pop_dictionary = {}\n",
    "    array2 = pop_pre_st['BG20'].unique()\n",
    "    [block_standardize(\n",
    "            x, \n",
    "            pop_dict=pop_dictionary, \n",
    "            og_df=pop_pre_st) \n",
    "        for x in array2]\n",
    "    ```\n",
    "    \n",
    "    Parameters:\n",
    "        tuple (tuple): A tuple containing the below.\n",
    "            block (str): The block_group to group by.\n",
    "            og_df (DataFrame): The dataframe we are \n",
    "                standardizing from.\n",
    "            year_start (int): Which year to start from.\n",
    "            year_end (int): Which year to end from.\n",
    "            weight (str): Which weight to use (such as \n",
    "                'wt_pop' pr 'wt_hh').\n",
    "    \n",
    "    Returns:\n",
    "        None. However, it appends the standardized values\n",
    "            per block group to a pre-defined dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    block_df = tuple[0]\n",
    "    og_df = tuple[1]\n",
    "    block = tuple[2]\n",
    "    year_start = tuple[3]\n",
    "    year_end = tuple[4]\n",
    "    weight = tuple[5]\n",
    "    \n",
    "    years_10_19 = [str(i) for i in range(year_start, 2020)]\n",
    "    years_2020_on = [str(i) for i in range(2020, end_year + 1)]\n",
    "        \n",
    "    # Step 1: Get a dataframe grouped by BG20\n",
    "    df = og_df.copy()\n",
    "    bg20_df = block_df.drop_duplicates()\n",
    "    bg20_df = bg20_df.fillna(0)\n",
    "        \n",
    "    # Step 2: Get dot product of 2010-2019 values with the target weight values values\n",
    "    array_10_19 = bg20_df[years_10_19].to_numpy().T\n",
    "    wt_array = bg20_df[weight].to_numpy()\n",
    "    dots = array_10_19.dot(wt_array)\n",
    "    \n",
    "    # Step 3: Append standardized 2010-2019 and \n",
    "    # the block's 2020 value to new dictionary\n",
    "    filtered = df[df['block']==block]\n",
    "    val_20_on = filtered[years_2020_on].iloc[0]\n",
    "    dots = np.append(dots, val_20_on)\n",
    "\n",
    "    # If the 2020 value is 0, then all years\n",
    "    # before then should be 0 also\n",
    "    if val_20_on[0] == 0:\n",
    "        dots = dots * 0\n",
    "\n",
    "    return {block : dots}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7d9b75eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>name</th>\n",
       "      <th>2013</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block group</th>\n",
       "      <th>block</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>BG10</th>\n",
       "      <th>BG20</th>\n",
       "      <th>wt_pop</th>\n",
       "      <th>wt_hu</th>\n",
       "      <th>wt_adult</th>\n",
       "      <th>wt_fam</th>\n",
       "      <th>wt_hh</th>\n",
       "      <th>parea</th>\n",
       "      <th>TRACT20</th>\n",
       "      <th>TRACT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1500000US010010206002</td>\n",
       "      <td>Block Group 2, Census Tract 206, Autauga Count...</td>\n",
       "      <td>800.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>2</td>\n",
       "      <td>010010206002</td>\n",
       "      <td>832.0000</td>\n",
       "      <td>694.0000</td>\n",
       "      <td>712.0000</td>\n",
       "      <td>910.0000</td>\n",
       "      <td>1150.0000</td>\n",
       "      <td>1118.0000</td>\n",
       "      <td>644.0000</td>\n",
       "      <td>590.0000</td>\n",
       "      <td>010010206002</td>\n",
       "      <td>010010206001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020600</td>\n",
       "      <td>01001020600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   geo_id                                               name  \\\n",
       "29  1500000US010010206002  Block Group 2, Census Tract 206, Autauga Count...   \n",
       "\n",
       "       2013 state county        tract block group         block     2014  \\\n",
       "29 800.0000    01    001  01001020600           2  010010206002 832.0000   \n",
       "\n",
       "       2015     2016     2017      2018      2019     2020     2021  \\\n",
       "29 694.0000 712.0000 910.0000 1150.0000 1118.0000 644.0000 590.0000   \n",
       "\n",
       "            BG10          BG20  wt_pop  wt_hu  wt_adult  wt_fam  wt_hh  parea  \\\n",
       "29  010010206002  010010206001  1.0000 1.0000    1.0000  1.0000 1.0000 1.0000   \n",
       "\n",
       "        TRACT20      TRACT10  \n",
       "29  01001020600  01001020600  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_pre_st[pop_pre_st['block'] == '010010206002']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44adf57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_testing = pop_pre_st[\n",
    "    pop_pre_st['BG20'].isin(\n",
    "        pop_pre_st['BG20'].unique()[:20])].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba6b71f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.5 s, sys: 4.29 s, total: 49.7 s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# testing numbers of blocks\n",
    "stand_testing = pop_pre_st[\n",
    "    pop_pre_st['BG20'].isin(\n",
    "        pop_pre_st['BG20'].unique()[:400])].copy()\n",
    "\n",
    "\n",
    "# Run the standardization using the block_standardize_tuple\n",
    "begin_year = 2013\n",
    "end_year = 2021\n",
    "\n",
    "main_df = stand_testing.copy()\n",
    "\n",
    "my_groups = main_df.groupby('BG20')\n",
    "keys = list(my_groups.groups.keys())\n",
    "\n",
    "dict2 = {}\n",
    "dict3 = [block_standardize_tuple((my_groups.get_group(keys[i]),\n",
    "                                pop_pre_st,\n",
    "                                keys[i], \n",
    "                                begin_year, \n",
    "                                end_year, \n",
    "                                'wt_pop'))\n",
    "        for i in range(len(keys))\n",
    "       ]\n",
    "\n",
    "\n",
    "for d in dict3:\n",
    "    dict2.update(d)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "10f87eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: '4.31 s', 200: '23.6 s', 400: '162 s'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to run number of blocks without parallelization\n",
    "{\n",
    "    20:'4.31 s',\n",
    "    200:'23.6 s',\n",
    "    400:'162 s'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "693f2c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'010010201001': array([637., 676., 649., 745., 692., 636., 730., 674., 693.]),\n",
       " '010010201002': array([1171., 1224., 1299., 1265., 1153., 1287., 1263., 1267., 1098.]),\n",
       " '010010202001': array([1383., 1289., 1074.,  960., 1020.,  810.,  835.,  706.,  844.]),\n",
       " '010010202002': array([ 972., 1053., 1082., 1236., 1152., 1218., 1124., 1051., 1166.]),\n",
       " '010010203001': array([2366., 2376., 2143., 2364., 2555., 2641., 2774., 2912., 2685.]),\n",
       " '010010203002': array([691., 921., 825., 772., 830., 835., 733., 782., 892.]),\n",
       " '010010204001': array([1088.,  970.,  785.,  729.,  651.,  653.,  761.,  720.,  733.]),\n",
       " '010010204002': array([1895., 1884., 2228., 2303., 2217., 1903., 1756., 1713., 1655.]),\n",
       " '010010204003': array([966., 949., 909., 978., 813., 705., 866., 707., 742.]),\n",
       " '010010204004': array([454., 469., 501., 553., 586., 570., 495., 399., 672.]),\n",
       " '010010205011': array([1859., 1961., 1936., 1947., 2068., 2150., 1972., 2006., 1847.]),\n",
       " '010010205012': array([1991., 1927., 1595., 1332., 1767., 1720., 2609., 2300., 2534.]),\n",
       " '010010205021': array([2076.63404127, 2074.26108422, 2145.15317619, 2150.49232956,\n",
       "        1818.27834209, 1783.57384519, 1784.16708445, 1951.        ,\n",
       "        1808.        ]),\n",
       " '010010205022': array([1288.46915583, 1286.99682999, 1330.98256463, 1334.29529779,\n",
       "        1128.16967937, 1106.63691387, 1107.00499533, 1149.        ,\n",
       "        1520.        ]),\n",
       " '010010205031': array([599.95502323, 599.26945828, 619.75071104, 621.29323217,\n",
       "        525.31413975, 515.28775242, 515.45914365, 891.        ,\n",
       "        899.        ]),\n",
       " '010010205032': array([1378.36677509, 1376.79172378, 1423.84638158, 1427.39024702,\n",
       "        1206.88306403, 1183.84793867, 1184.24170149,  885.        ,\n",
       "         903.        ]),\n",
       " '010010205033': array([1657.57500458, 1655.68090373, 1712.26716656, 1716.52889347,\n",
       "        1451.35477476, 1423.65354985, 1424.12707507, 1492.        ,\n",
       "        1372.        ]),\n",
       " '010010206002': array([714.69748246, 808.4193149 , 865.14568716, 830.34255056,\n",
       "        742.64960792, 700.17333884, 698.80313661, 644.        ,\n",
       "        590.        ]),\n",
       " '010010206003': array([1893.30251754, 2141.5806851 , 2291.85431284, 2199.65744944,\n",
       "        1967.35039208, 1854.82666116, 1851.19686339, 1840.        ,\n",
       "        1991.        ]),\n",
       " '010010208031': array([ 729.75922671,  718.24428822,  770.63725835,  848.93884007,\n",
       "         932.42214411,  892.1198594 ,  909.10439367,  811.        ,\n",
       "        1248.        ])}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b42984d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid_block</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010010202001</td>\n",
       "      <td>1383.0000</td>\n",
       "      <td>1289.0000</td>\n",
       "      <td>1074.0000</td>\n",
       "      <td>960.0000</td>\n",
       "      <td>1020.0000</td>\n",
       "      <td>810.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>706.0000</td>\n",
       "      <td>844.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010010202002</td>\n",
       "      <td>972.0000</td>\n",
       "      <td>1053.0000</td>\n",
       "      <td>1082.0000</td>\n",
       "      <td>1236.0000</td>\n",
       "      <td>1152.0000</td>\n",
       "      <td>1218.0000</td>\n",
       "      <td>1124.0000</td>\n",
       "      <td>1051.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010010203001</td>\n",
       "      <td>2366.0000</td>\n",
       "      <td>2376.0000</td>\n",
       "      <td>2143.0000</td>\n",
       "      <td>2364.0000</td>\n",
       "      <td>2555.0000</td>\n",
       "      <td>2641.0000</td>\n",
       "      <td>2774.0000</td>\n",
       "      <td>2912.0000</td>\n",
       "      <td>2685.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>010010203002</td>\n",
       "      <td>691.0000</td>\n",
       "      <td>921.0000</td>\n",
       "      <td>825.0000</td>\n",
       "      <td>772.0000</td>\n",
       "      <td>830.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>733.0000</td>\n",
       "      <td>782.0000</td>\n",
       "      <td>892.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>010010204001</td>\n",
       "      <td>1088.0000</td>\n",
       "      <td>970.0000</td>\n",
       "      <td>785.0000</td>\n",
       "      <td>729.0000</td>\n",
       "      <td>651.0000</td>\n",
       "      <td>653.0000</td>\n",
       "      <td>761.0000</td>\n",
       "      <td>720.0000</td>\n",
       "      <td>733.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>010010204002</td>\n",
       "      <td>1895.0000</td>\n",
       "      <td>1884.0000</td>\n",
       "      <td>2228.0000</td>\n",
       "      <td>2303.0000</td>\n",
       "      <td>2217.0000</td>\n",
       "      <td>1903.0000</td>\n",
       "      <td>1756.0000</td>\n",
       "      <td>1713.0000</td>\n",
       "      <td>1655.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>010010204003</td>\n",
       "      <td>966.0000</td>\n",
       "      <td>949.0000</td>\n",
       "      <td>909.0000</td>\n",
       "      <td>978.0000</td>\n",
       "      <td>813.0000</td>\n",
       "      <td>705.0000</td>\n",
       "      <td>866.0000</td>\n",
       "      <td>707.0000</td>\n",
       "      <td>742.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>010010204004</td>\n",
       "      <td>454.0000</td>\n",
       "      <td>469.0000</td>\n",
       "      <td>501.0000</td>\n",
       "      <td>553.0000</td>\n",
       "      <td>586.0000</td>\n",
       "      <td>570.0000</td>\n",
       "      <td>495.0000</td>\n",
       "      <td>399.0000</td>\n",
       "      <td>672.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>010010205011</td>\n",
       "      <td>1859.0000</td>\n",
       "      <td>1961.0000</td>\n",
       "      <td>1936.0000</td>\n",
       "      <td>1947.0000</td>\n",
       "      <td>2068.0000</td>\n",
       "      <td>2150.0000</td>\n",
       "      <td>1972.0000</td>\n",
       "      <td>2006.0000</td>\n",
       "      <td>1847.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>010010205012</td>\n",
       "      <td>1991.0000</td>\n",
       "      <td>1927.0000</td>\n",
       "      <td>1595.0000</td>\n",
       "      <td>1332.0000</td>\n",
       "      <td>1767.0000</td>\n",
       "      <td>1720.0000</td>\n",
       "      <td>2609.0000</td>\n",
       "      <td>2300.0000</td>\n",
       "      <td>2534.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>010010205021</td>\n",
       "      <td>2076.6340</td>\n",
       "      <td>2074.2611</td>\n",
       "      <td>2145.1532</td>\n",
       "      <td>2150.4923</td>\n",
       "      <td>1818.2783</td>\n",
       "      <td>1783.5738</td>\n",
       "      <td>1784.1671</td>\n",
       "      <td>1951.0000</td>\n",
       "      <td>1808.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>010010205022</td>\n",
       "      <td>1288.4692</td>\n",
       "      <td>1286.9968</td>\n",
       "      <td>1330.9826</td>\n",
       "      <td>1334.2953</td>\n",
       "      <td>1128.1697</td>\n",
       "      <td>1106.6369</td>\n",
       "      <td>1107.0050</td>\n",
       "      <td>1149.0000</td>\n",
       "      <td>1520.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>010010205031</td>\n",
       "      <td>599.9550</td>\n",
       "      <td>599.2695</td>\n",
       "      <td>619.7507</td>\n",
       "      <td>621.2932</td>\n",
       "      <td>525.3141</td>\n",
       "      <td>515.2878</td>\n",
       "      <td>515.4591</td>\n",
       "      <td>891.0000</td>\n",
       "      <td>899.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>010010205032</td>\n",
       "      <td>1378.3668</td>\n",
       "      <td>1376.7917</td>\n",
       "      <td>1423.8464</td>\n",
       "      <td>1427.3902</td>\n",
       "      <td>1206.8831</td>\n",
       "      <td>1183.8479</td>\n",
       "      <td>1184.2417</td>\n",
       "      <td>885.0000</td>\n",
       "      <td>903.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>010010205033</td>\n",
       "      <td>1657.5750</td>\n",
       "      <td>1655.6809</td>\n",
       "      <td>1712.2672</td>\n",
       "      <td>1716.5289</td>\n",
       "      <td>1451.3548</td>\n",
       "      <td>1423.6535</td>\n",
       "      <td>1424.1271</td>\n",
       "      <td>1492.0000</td>\n",
       "      <td>1372.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>010010206002</td>\n",
       "      <td>714.6975</td>\n",
       "      <td>808.4193</td>\n",
       "      <td>865.1457</td>\n",
       "      <td>830.3426</td>\n",
       "      <td>742.6496</td>\n",
       "      <td>700.1733</td>\n",
       "      <td>698.8031</td>\n",
       "      <td>644.0000</td>\n",
       "      <td>590.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>010010206003</td>\n",
       "      <td>1893.3025</td>\n",
       "      <td>2141.5807</td>\n",
       "      <td>2291.8543</td>\n",
       "      <td>2199.6574</td>\n",
       "      <td>1967.3504</td>\n",
       "      <td>1854.8267</td>\n",
       "      <td>1851.1969</td>\n",
       "      <td>1840.0000</td>\n",
       "      <td>1991.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>010010208031</td>\n",
       "      <td>729.7592</td>\n",
       "      <td>718.2443</td>\n",
       "      <td>770.6373</td>\n",
       "      <td>848.9388</td>\n",
       "      <td>932.4221</td>\n",
       "      <td>892.1199</td>\n",
       "      <td>909.1044</td>\n",
       "      <td>811.0000</td>\n",
       "      <td>1248.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     geoid_block      2013      2014      2015      2016      2017      2018  \\\n",
       "0   010010201001  637.0000  676.0000  649.0000  745.0000  692.0000  636.0000   \n",
       "1   010010201002 1171.0000 1224.0000 1299.0000 1265.0000 1153.0000 1287.0000   \n",
       "2   010010202001 1383.0000 1289.0000 1074.0000  960.0000 1020.0000  810.0000   \n",
       "3   010010202002  972.0000 1053.0000 1082.0000 1236.0000 1152.0000 1218.0000   \n",
       "4   010010203001 2366.0000 2376.0000 2143.0000 2364.0000 2555.0000 2641.0000   \n",
       "5   010010203002  691.0000  921.0000  825.0000  772.0000  830.0000  835.0000   \n",
       "6   010010204001 1088.0000  970.0000  785.0000  729.0000  651.0000  653.0000   \n",
       "7   010010204002 1895.0000 1884.0000 2228.0000 2303.0000 2217.0000 1903.0000   \n",
       "8   010010204003  966.0000  949.0000  909.0000  978.0000  813.0000  705.0000   \n",
       "9   010010204004  454.0000  469.0000  501.0000  553.0000  586.0000  570.0000   \n",
       "10  010010205011 1859.0000 1961.0000 1936.0000 1947.0000 2068.0000 2150.0000   \n",
       "11  010010205012 1991.0000 1927.0000 1595.0000 1332.0000 1767.0000 1720.0000   \n",
       "12  010010205021 2076.6340 2074.2611 2145.1532 2150.4923 1818.2783 1783.5738   \n",
       "13  010010205022 1288.4692 1286.9968 1330.9826 1334.2953 1128.1697 1106.6369   \n",
       "14  010010205031  599.9550  599.2695  619.7507  621.2932  525.3141  515.2878   \n",
       "15  010010205032 1378.3668 1376.7917 1423.8464 1427.3902 1206.8831 1183.8479   \n",
       "16  010010205033 1657.5750 1655.6809 1712.2672 1716.5289 1451.3548 1423.6535   \n",
       "17  010010206002  714.6975  808.4193  865.1457  830.3426  742.6496  700.1733   \n",
       "18  010010206003 1893.3025 2141.5807 2291.8543 2199.6574 1967.3504 1854.8267   \n",
       "19  010010208031  729.7592  718.2443  770.6373  848.9388  932.4221  892.1199   \n",
       "\n",
       "        2019      2020      2021  \n",
       "0   730.0000  674.0000  693.0000  \n",
       "1  1263.0000 1267.0000 1098.0000  \n",
       "2   835.0000  706.0000  844.0000  \n",
       "3  1124.0000 1051.0000 1166.0000  \n",
       "4  2774.0000 2912.0000 2685.0000  \n",
       "5   733.0000  782.0000  892.0000  \n",
       "6   761.0000  720.0000  733.0000  \n",
       "7  1756.0000 1713.0000 1655.0000  \n",
       "8   866.0000  707.0000  742.0000  \n",
       "9   495.0000  399.0000  672.0000  \n",
       "10 1972.0000 2006.0000 1847.0000  \n",
       "11 2609.0000 2300.0000 2534.0000  \n",
       "12 1784.1671 1951.0000 1808.0000  \n",
       "13 1107.0050 1149.0000 1520.0000  \n",
       "14  515.4591  891.0000  899.0000  \n",
       "15 1184.2417  885.0000  903.0000  \n",
       "16 1424.1271 1492.0000 1372.0000  \n",
       "17  698.8031  644.0000  590.0000  \n",
       "18 1851.1969 1840.0000 1991.0000  \n",
       "19  909.1044  811.0000 1248.0000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_list = []\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    column_list.append(f'{i}')\n",
    "\n",
    "standardized_df = (pd.DataFrame.from_dict(dict2, \n",
    "                   orient='index', columns=column_list)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'index':'geoid_block'}))\n",
    "\n",
    "standardized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded1f1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6507141d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 17:09:31 WARN Utils: Your hostname, Austin-Wolffs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.16.225.161 instead (on interface en0)\n",
      "23/02/15 17:09:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/WonderWolff/Real_Estate/housing_supply_and_demand/venv/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/WonderWolff/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/WonderWolff/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.hadoop#hadoop-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7c162c05-8789-4ca1-9187-56ddb8e14167;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;2.10.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;2.10.2 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound xmlenc#xmlenc;0.52 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.4 in central\n",
      "\tfound commons-io#commons-io;2.5 in central\n",
      "\tfound commons-net#commons-net;3.1 in central\n",
      "\tfound commons-collections#commons-collections;3.2.2 in central\n",
      "\tfound org.mortbay.jetty#jetty-sslengine;6.1.26 in central\n",
      "\tfound ch.qos.reload4j#reload4j;1.2.18.3 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound commons-configuration#commons-configuration;1.6 in central\n",
      "\tfound commons-digester#commons-digester;1.8 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.9.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
      "\tfound org.slf4j#slf4j-reload4j;1.7.36 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.apache.avro#avro;1.7.7 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.0.5 in central\n",
      "\tfound org.apache.commons#commons-compress;1.21 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;2.10.2 in central\n",
      "\tfound com.nimbusds#nimbus-jose-jwt;7.9 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound net.minidev#json-smart;1.3.3 in central\n",
      "\tfound org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.server#apacheds-i18n;2.0.0-M15 in central\n",
      "\tfound org.apache.directory.api#api-asn1-api;1.0.0-M20 in central\n",
      "\tfound org.apache.directory.api#api-util;1.0.0-M20 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.4.14 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.9 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.apache.yetus#audience-annotations;0.5.0 in central\n",
      "\tfound io.netty#netty;3.10.6.Final in central\n",
      "\tfound org.apache.curator#curator-framework;2.13.0 in central\n",
      "\tfound org.apache.curator#curator-client;2.13.0 in central\n",
      "\tfound org.apache.curator#curator-recipes;2.13.0 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in central\n",
      "\tfound com.fasterxml.woodstox#woodstox-core;5.3.0 in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound jline#jline;0.9.94 in central\n",
      "\tfound org.apache.hadoop#hadoop-hdfs-client;2.10.2 in central\n",
      "\tfound com.squareup.okhttp#okhttp;2.7.5 in central\n",
      "\tfound com.squareup.okio#okio;1.6.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-app;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-common;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-common;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-api;2.10.2 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.2 in central\n",
      "\tfound javax.xml.stream#stax-api;1.0-2 in central\n",
      "\tfound javax.activation#activation;1.1 in central\n",
      "\tfound org.mortbay.jetty#jetty-util;6.1.26 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-client;1.9 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.google.inject#guice;3.0 in central\n",
      "\tfound javax.inject#javax.inject;1 in central\n",
      "\tfound aopalliance#aopalliance;1.0 in central\n",
      "\tfound org.sonatype.sisu.inject#cglib;2.2.1-v20090111 in central\n",
      "\tfound asm#asm;3.2 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.9 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.9 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound com.sun.jersey.contribs#jersey-guice;1.9 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-client;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-core;2.10.2 in central\n",
      "\tfound javax.servlet#servlet-api;2.5 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-server-common;2.10.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-registry;2.10.2 in central\n",
      "\tfound org.fusesource.leveldbjni#leveldbjni-all;1.8 in central\n",
      "\tfound org.apache.geronimo.specs#geronimo-jcache_1.0_spec;1.0-alpha-1 in central\n",
      "\tfound org.ehcache#ehcache;3.3.1 in central\n",
      "\tfound com.zaxxer#HikariCP-java7;2.4.12 in central\n",
      "\tfound com.microsoft.sqlserver#mssql-jdbc;6.2.1.jre7 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.10.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/2.10.2/hadoop-aws-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;2.10.2!hadoop-aws.jar (189ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/2.10.2/hadoop-client-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client;2.10.2!hadoop-client.jar (165ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.271/aws-java-sdk-bundle-1.11.271.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.271!aws-java-sdk-bundle.jar (126842ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-lang3;3.4!commons-lang3.jar (695ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.10.2/hadoop-common-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-common;2.10.2!hadoop-common.jar (6374ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs-client/2.10.2/hadoop-hdfs-client-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-hdfs-client;2.10.2!hadoop-hdfs-client.jar (6760ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.10.2/hadoop-mapreduce-client-app-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-app;2.10.2!hadoop-mapreduce-client-app.jar (928ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.10.2/hadoop-yarn-api-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-api;2.10.2!hadoop-yarn-api.jar (4620ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.10.2/hadoop-mapreduce-client-core-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-core;2.10.2!hadoop-mapreduce-client-core.jar (2565ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.10.2/hadoop-mapreduce-client-jobclient-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-jobclient;2.10.2!hadoop-mapreduce-client-jobclient.jar (119ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.10.2/hadoop-annotations-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-annotations;2.10.2!hadoop-annotations.jar (78ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar ...\n",
      "\t[SUCCESSFUL ] commons-cli#commons-cli;1.2!commons-cli.jar (65ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-math3;3.1.1!commons-math3.jar (3321ms)\n",
      "downloading https://repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar ...\n",
      "\t[SUCCESSFUL ] xmlenc#xmlenc;0.52!xmlenc.jar (55ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.13!httpclient.jar (1594ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...\n",
      "\t[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (205ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-io/commons-io/2.5/commons-io-2.5.jar ...\n",
      "\t[SUCCESSFUL ] commons-io#commons-io;2.5!commons-io.jar (436ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar ...\n",
      "\t[SUCCESSFUL ] commons-net#commons-net;3.1!commons-net.jar (453ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar ...\n",
      "\t[SUCCESSFUL ] commons-collections#commons-collections;3.2.2!commons-collections.jar (925ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar ...\n",
      "\t[SUCCESSFUL ] org.mortbay.jetty#jetty-sslengine;6.1.26!jetty-sslengine.jar (94ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
      "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (74ms)\n",
      "downloading https://repo1.maven.org/maven2/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar ...\n",
      "\t[SUCCESSFUL ] ch.qos.reload4j#reload4j;1.2.18.3!reload4j.jar (520ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar ...\n",
      "\t[SUCCESSFUL ] commons-lang#commons-lang;2.6!commons-lang.jar (461ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar ...\n",
      "\t[SUCCESSFUL ] commons-configuration#commons-configuration;1.6!commons-configuration.jar (468ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar ...\n",
      "\t[SUCCESSFUL ] commons-digester#commons-digester;1.8!commons-digester.jar (226ms)\n",
      "downloading https://repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar ...\n",
      "\t[SUCCESSFUL ] commons-beanutils#commons-beanutils;1.9.4!commons-beanutils.jar (396ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.36!slf4j-api.jar (71ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-reload4j;1.7.36!slf4j-reload4j.jar (62ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.9.13!jackson-core-asl.jar (320ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.9.13!jackson-mapper-asl.jar (1239ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/avro/avro/1.7.7/avro-1.7.7.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.avro#avro;1.7.7!avro.jar(bundle) (700ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;2.5.0!protobuf-java.jar(bundle) (849ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.gson#gson;2.2.4!gson.jar (290ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.10.2/hadoop-auth-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-auth;2.10.2!hadoop-auth.jar (202ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.curator#curator-client;2.13.0!curator-client.jar(bundle) (3855ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.curator#curator-recipes;2.13.0!curator-recipes.jar(bundle) (445ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (56ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.htrace#htrace-core4;4.1.0-incubating!htrace-core4.jar (2413ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.14!zookeeper.jar (1384ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-compress;1.21!commons-compress.jar (1619ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.woodstox#stax2-api;4.2.1!stax2-api.jar(bundle) (321ms)\n",
      "downloading https://repo1.maven.org/maven2/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar ...\n",
      "\t[SUCCESSFUL ] com.fasterxml.woodstox#woodstox-core;5.3.0!woodstox-core.jar(bundle) (854ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.13!httpcore.jar (532ms)\n",
      "downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...\n",
      "\t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (63ms)\n",
      "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar ...\n",
      "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.5!snappy-java.jar(bundle) (1972ms)\n",
      "downloading https://repo1.maven.org/maven2/com/nimbusds/nimbus-jose-jwt/7.9/nimbus-jose-jwt-7.9.jar ...\n",
      "\t[SUCCESSFUL ] com.nimbusds#nimbus-jose-jwt;7.9!nimbus-jose-jwt.jar (537ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15!apacheds-kerberos-codec.jar(bundle) (1088ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.curator#curator-framework;2.13.0!curator-framework.jar(bundle) (322ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...\n",
      "\t[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (51ms)\n",
      "downloading https://repo1.maven.org/maven2/net/minidev/json-smart/1.3.3/json-smart-1.3.3.jar ...\n",
      "\t[SUCCESSFUL ] net.minidev#json-smart;1.3.3!json-smart.jar(bundle) (75ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.directory.server#apacheds-i18n;2.0.0-M15!apacheds-i18n.jar(bundle) (79ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.directory.api#api-asn1-api;1.0.0-M20!api-asn1-api.jar(bundle) (45ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.directory.api#api-util;1.0.0-M20!api-util.jar(bundle) (101ms)\n",
      "downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar ...\n",
      "\t[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.9!spotbugs-annotations.jar (65ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.yetus#audience-annotations;0.5.0!audience-annotations.jar (71ms)\n",
      "downloading https://repo1.maven.org/maven2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar ...\n",
      "\t[SUCCESSFUL ] io.netty#netty;3.10.6.Final!netty.jar(bundle) (1983ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar ...\n",
      "\t[SUCCESSFUL ] javax.servlet.jsp#jsp-api;2.1!jsp-api.jar (152ms)\n",
      "downloading https://repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t[SUCCESSFUL ] log4j#log4j;1.2.17!log4j.jar(bundle) (780ms)\n",
      "downloading https://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...\n",
      "\t[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (131ms)\n",
      "downloading https://repo1.maven.org/maven2/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar ...\n",
      "\t[SUCCESSFUL ] com.squareup.okhttp#okhttp;2.7.5!okhttp.jar (526ms)\n",
      "downloading https://repo1.maven.org/maven2/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar ...\n",
      "\t[SUCCESSFUL ] com.squareup.okio#okio;1.6.0!okio.jar (101ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.10.2/hadoop-mapreduce-client-common-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-common;2.10.2!hadoop-mapreduce-client-common.jar (1260ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.10.2/hadoop-mapreduce-client-shuffle-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-mapreduce-client-shuffle;2.10.2!hadoop-mapreduce-client-shuffle.jar (130ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.10.2/hadoop-yarn-common-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-common;2.10.2!hadoop-yarn-common.jar (3253ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.10.2/hadoop-yarn-client-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-client;2.10.2!hadoop-yarn-client.jar (442ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar ...\n",
      "\t[SUCCESSFUL ] javax.xml.bind#jaxb-api;2.2.2!jaxb-api.jar (160ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar ...\n",
      "\t[SUCCESSFUL ] org.mortbay.jetty#jetty-util;6.1.26!jetty-util.jar (275ms)\n",
      "downloading https://repo1.maven.org/maven2/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar ...\n",
      "\t[SUCCESSFUL ] com.sun.jersey#jersey-core;1.9!jersey-core.jar(bundle) (747ms)\n",
      "downloading https://repo1.maven.org/maven2/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar ...\n",
      "\t[SUCCESSFUL ] com.sun.jersey#jersey-client;1.9!jersey-client.jar(bundle) (210ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-jaxrs;1.9.13!jackson-jaxrs.jar (47ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-xc;1.9.13!jackson-xc.jar (52ms)\n",
      "downloading https://repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar ...\n",
      "\t[SUCCESSFUL ] com.google.inject#guice;3.0!guice.jar (1088ms)\n",
      "downloading https://repo1.maven.org/maven2/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar ...\n",
      "\t[SUCCESSFUL ] com.sun.jersey#jersey-server;1.9!jersey-server.jar(bundle) (1138ms)\n",
      "downloading https://repo1.maven.org/maven2/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar ...\n",
      "\t[SUCCESSFUL ] com.sun.jersey#jersey-json;1.9!jersey-json.jar(bundle) (231ms)\n",
      "downloading https://repo1.maven.org/maven2/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar ...\n",
      "\t[SUCCESSFUL ] com.sun.jersey.contribs#jersey-guice;1.9!jersey-guice.jar (51ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar ...\n",
      "\t[SUCCESSFUL ] javax.xml.stream#stax-api;1.0-2!stax-api.jar (52ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/activation/activation/1.1/activation-1.1.jar ...\n",
      "\t[SUCCESSFUL ] javax.activation#activation;1.1!activation.jar (72ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...\n",
      "\t[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (46ms)\n",
      "downloading https://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...\n",
      "\t[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (43ms)\n",
      "downloading https://repo1.maven.org/maven2/org/sonatype/sisu/inject/cglib/2.2.1-v20090111/cglib-2.2.1-v20090111.jar ...\n",
      "\t[SUCCESSFUL ] org.sonatype.sisu.inject#cglib;2.2.1-v20090111!cglib.jar (357ms)\n",
      "downloading https://repo1.maven.org/maven2/asm/asm/3.2/asm-3.2.jar ...\n",
      "\t[SUCCESSFUL ] asm#asm;3.2!asm.jar (69ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jettison#jettison;1.1!jettison.jar(bundle) (102ms)\n",
      "downloading https://repo1.maven.org/maven2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar ...\n",
      "\t[SUCCESSFUL ] com.sun.xml.bind#jaxb-impl;2.2.3-1!jaxb-impl.jar (1414ms)\n",
      "downloading https://repo1.maven.org/maven2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar ...\n",
      "\t[SUCCESSFUL ] javax.servlet#servlet-api;2.5!servlet-api.jar (164ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.10.2/hadoop-yarn-server-common-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-server-common;2.10.2!hadoop-yarn-server-common.jar (2113ms)\n",
      "downloading https://repo1.maven.org/maven2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar ...\n",
      "\t[SUCCESSFUL ] org.fusesource.leveldbjni#leveldbjni-all;1.8!leveldbjni-all.jar(bundle) (1654ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-registry/2.10.2/hadoop-yarn-registry-2.10.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-yarn-registry;2.10.2!hadoop-yarn-registry.jar (213ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.geronimo.specs#geronimo-jcache_1.0_spec;1.0-alpha-1!geronimo-jcache_1.0_spec.jar(bundle) (90ms)\n",
      "downloading https://repo1.maven.org/maven2/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.ehcache#ehcache;3.3.1!ehcache.jar (2742ms)\n",
      "downloading https://repo1.maven.org/maven2/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar ...\n",
      "\t[SUCCESSFUL ] com.zaxxer#HikariCP-java7;2.4.12!HikariCP-java7.jar(bundle) (211ms)\n",
      "downloading https://repo1.maven.org/maven2/com/microsoft/sqlserver/mssql-jdbc/6.2.1.jre7/mssql-jdbc-6.2.1.jre7.jar ...\n",
      "\t[SUCCESSFUL ] com.microsoft.sqlserver#mssql-jdbc;6.2.1.jre7!mssql-jdbc.jar (1256ms)\n",
      ":: resolution report :: resolve 25467ms :: artifacts dl 201894ms\n",
      "\t:: modules in use:\n",
      "\taopalliance#aopalliance;1.0 from central in [default]\n",
      "\tasm#asm;3.2 from central in [default]\n",
      "\tch.qos.reload4j#reload4j;1.2.18.3 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\tcom.fasterxml.woodstox#woodstox-core;5.3.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.9 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.inject#guice;3.0 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.microsoft.sqlserver#mssql-jdbc;6.2.1.jre7 from central in [default]\n",
      "\tcom.nimbusds#nimbus-jose-jwt;7.9 from central in [default]\n",
      "\tcom.squareup.okhttp#okhttp;2.7.5 from central in [default]\n",
      "\tcom.squareup.okio#okio;1.6.0 from central in [default]\n",
      "\tcom.sun.jersey#jersey-client;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.9 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.9 from central in [default]\n",
      "\tcom.sun.jersey.contribs#jersey-guice;1.9 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcom.zaxxer#HikariCP-java7;2.4.12 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.9.4 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.4 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
      "\tcommons-configuration#commons-configuration;1.6 from central in [default]\n",
      "\tcommons-digester#commons-digester;1.8 from central in [default]\n",
      "\tcommons-io#commons-io;2.5 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.1 from central in [default]\n",
      "\tio.netty#netty;3.10.6.Final from central in [default]\n",
      "\tjavax.activation#activation;1.1 from central in [default]\n",
      "\tjavax.inject#javax.inject;1 from central in [default]\n",
      "\tjavax.servlet#servlet-api;2.5 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.2 from central in [default]\n",
      "\tjavax.xml.stream#stax-api;1.0-2 from central in [default]\n",
      "\tjline#jline;0.9.94 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.minidev#json-smart;1.3.3 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.7 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.21 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.4 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.curator#curator-client;2.13.0 from central in [default]\n",
      "\torg.apache.curator#curator-framework;2.13.0 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;2.13.0 from central in [default]\n",
      "\torg.apache.directory.api#api-asn1-api;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.api#api-util;1.0.0-M20 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-i18n;2.0.0-M15 from central in [default]\n",
      "\torg.apache.directory.server#apacheds-kerberos-codec;2.0.0-M15 from central in [default]\n",
      "\torg.apache.geronimo.specs#geronimo-jcache_1.0_spec;1.0-alpha-1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-hdfs-client;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-app;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-common;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-core;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-jobclient;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-shuffle;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-api;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-client;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-common;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-registry;2.10.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-server-common;2.10.2 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.yetus#audience-annotations;0.5.0 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.4.14 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.codehaus.woodstox#stax2-api;4.2.1 from central in [default]\n",
      "\torg.ehcache#ehcache;3.3.1 from central in [default]\n",
      "\torg.fusesource.leveldbjni#leveldbjni-all;1.8 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-sslengine;6.1.26 from central in [default]\n",
      "\torg.mortbay.jetty#jetty-util;6.1.26 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
      "\torg.slf4j#slf4j-reload4j;1.7.36 from central in [default]\n",
      "\torg.sonatype.sisu.inject#cglib;2.2.1-v20090111 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.0.5 from central in [default]\n",
      "\txmlenc#xmlenc;0.52 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   91  |   91  |   91  |   0   ||   91  |   91  |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7c162c05-8789-4ca1-9187-56ddb8e14167\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t91 artifacts copied, 0 already retrieved (129475kB/805ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/15 17:13:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Standardize Block Groups</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd8368b15b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST ASSIGNING THIS TO SPARK\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    master('local'). \\\n",
    "    config(\"spark.driver.bindAddress\",\"127.0.0.1\"). \\\n",
    "    config(\"spark.driver.host\",\"127.0.0.1\"). \\\n",
    "    config(\"spark.jars.packages\", \n",
    "           \"org.apache.hadoop:hadoop-aws:2.10.2,org.apache.hadoop:hadoop-client:2.10.2\"). \\\n",
    "    config(\"spark.jars.excludes\", \n",
    "           \"com.google.guava:guava\"). \\\n",
    "    appName('Standardize Block Groups'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "### IF WORKING LOCALLY, GET AWS CREDENTIALS USING THE BELOW\n",
    "if os.environ.get(\"ENVIRON\") == \"LOCAL\":\n",
    "    spark.sparkContext._jsc.hadoopConfiguration().set(\n",
    "        \"fs.s3a.aws.credentials.provider\",\n",
    "        \"com.amazonaws.auth.DefaultAWSCredentialsProviderChain\"\n",
    "    )\n",
    "    print(\"Set Default AWS Credentials Provider\")\n",
    "\n",
    "spark\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49adbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de5bb63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set Hadoop configurations\n",
    "# hadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "# hadoop_conf.set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "# hadoop_conf.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n",
    "# hadoop_conf.set(\"fs.s3a.aws.credentials.provider\", \n",
    "#                 \"org.apache.hadoop.fs.s3a.BasicAWSCredentialsProvider\")\n",
    "# hadoop_conf.set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "329a3389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+------+-----------+------------+------+------+------+------+------+------+------+------+------------+------------+------+-----+--------+------+-----+-----------+-----------+-----------+\n",
      "|              geo_id|  2013|state|county|      tract|       block|  2014|  2015|  2016|  2017|  2018|  2019|  2020|  2021|        BG10|        BG20|wt_pop|wt_hu|wt_adult|wt_fam|wt_hh|      parea|    TRACT20|    TRACT10|\n",
      "+--------------------+------+-----+------+-----------+------------+------+------+------+------+------+------+------+------+------------+------------+------+-----+--------+------+-----+-----------+-----------+-----------+\n",
      "|1500000US01001020...| 637.0|   01|   001|01001020100|010010201001| 676.0| 649.0| 745.0| 692.0| 636.0| 730.0| 674.0| 693.0|010010201001|010010201001|   1.0|  1.0|     1.0|   1.0|  1.0|        1.0|01001020100|01001020100|\n",
      "|1500000US01001020...| 637.0|   01|   001|01001020100|010010201001| 676.0| 649.0| 745.0| 692.0| 636.0| 730.0| 674.0| 693.0|010010201001|010010201001|   1.0|  1.0|     1.0|   1.0|  1.0|        1.0|01001020100|01001020100|\n",
      "|1500000US01001020...|1171.0|   01|   001|01001020100|010010201002|1224.0|1299.0|1265.0|1153.0|1287.0|1263.0|1267.0|1098.0|010010201002|010010201002|   1.0|  1.0|     1.0|   1.0|  1.0|  0.9987746|01001020100|01001020100|\n",
      "|1500000US01001020...|1171.0|   01|   001|01001020100|010010201002|1224.0|1299.0|1265.0|1153.0|1287.0|1263.0|1267.0|1098.0|010010201002|010010208031|   0.0|  0.0|     0.0|   0.0|  0.0|0.001225433|01001020803|01001020100|\n",
      "|1500000US01001020...|1383.0|   01|   001|01001020200|010010202001|1289.0|1074.0| 960.0|1020.0| 810.0| 835.0| 706.0| 844.0|010010202001|010010202001|   1.0|  1.0|     1.0|   1.0|  1.0|        1.0|01001020200|01001020200|\n",
      "+--------------------+------+-----+------+-----------+------------+------+------+------+------+------+------+------+------+------------+------------+------+-----+--------+------+-----+-----------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# S3 URI\n",
    "s3_location = \"s3a://real-estate-wolff/census-data/block-groups/raw/population_blocks_raw.csv\"\n",
    "\n",
    "# READ IN DATAFRAME\n",
    "spark_s3_df = spark.read.load(s3_location, format=\"csv\", header=True)\n",
    "\n",
    "# CHANGE TYPE FOR THE YEAR COLUMNS\n",
    "for i in range(start_year, end_year + 1):\n",
    "    spark_s3_df = spark_s3_df.withColumn(\n",
    "        str(i), spark_col(str(i)).cast(\"float\")\n",
    "    )\n",
    "    \n",
    "# CHNAGE TYPE FOR THE CROSSWALK MULTIPLIER COLUMNS\n",
    "spark_s3_df = spark_s3_df.withColumn('wt_pop', spark_col('wt_pop').cast(\"float\")). \\\n",
    "    withColumn('wt_hu', spark_col('wt_hu').cast(\"float\")). \\\n",
    "    withColumn('wt_adult', spark_col('wt_adult').cast(\"float\")). \\\n",
    "    withColumn('wt_fam', spark_col('wt_fam').cast(\"float\")). \\\n",
    "    withColumn('wt_hh', spark_col('wt_hh').cast(\"float\")). \\\n",
    "    withColumn('parea', spark_col('parea').cast(\"float\"))\n",
    "\n",
    "\n",
    "spark_s3_df.show(5)\n",
    "\n",
    "\n",
    "#2)\n",
    "#### THEN GET TO TESTING THE SPARK JOB LOCALLY FOR A SPARK DATAFRAME\n",
    "#### WITH ONLY 200 UNIQUE BG20'S\n",
    "\n",
    "#3)\n",
    "#### THEN TEST SPARK JOB 'YARN' ON EMR FOR 200 UNIQUES, AND TIME IT AND \n",
    "#### TRACK COST. THEN TRACK TIME AND COST FOR 2,000. IF NEED BE, ALSO\n",
    "#### RUN THE EXPERIMENT WITH 22,000 UNIQUES, TRACKING TIME AND COST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c1979055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geo_id: string (nullable = true)\n",
      " |-- 2013: float (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- tract: string (nullable = true)\n",
      " |-- block: string (nullable = true)\n",
      " |-- 2014: float (nullable = true)\n",
      " |-- 2015: float (nullable = true)\n",
      " |-- 2016: float (nullable = true)\n",
      " |-- 2017: float (nullable = true)\n",
      " |-- 2018: float (nullable = true)\n",
      " |-- 2019: float (nullable = true)\n",
      " |-- 2020: float (nullable = true)\n",
      " |-- 2021: float (nullable = true)\n",
      " |-- BG10: string (nullable = true)\n",
      " |-- BG20: string (nullable = true)\n",
      " |-- wt_pop: float (nullable = true)\n",
      " |-- wt_hu: float (nullable = true)\n",
      " |-- wt_adult: float (nullable = true)\n",
      " |-- wt_fam: float (nullable = true)\n",
      " |-- wt_hh: float (nullable = true)\n",
      " |-- parea: float (nullable = true)\n",
      " |-- TRACT20: string (nullable = true)\n",
      " |-- TRACT10: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_s3_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df3ce1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test getting 400 unique blocks\n",
    "spark_key_list = [i['BG20'] for i in spark_s3_df.select('BG20').limit(10).collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4107c861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark_s3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "45c9b101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 73:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+------+-----------+------------+------+------+------+------+------+------+------+------+------------+------------+----------+----------+----------+----------+---------+------------+-----------+-----------+\n",
      "|              geo_id|  2013|state|county|      tract|       block|  2014|  2015|  2016|  2017|  2018|  2019|  2020|  2021|        BG10|        BG20|    wt_pop|     wt_hu|  wt_adult|    wt_fam|    wt_hh|       parea|    TRACT20|    TRACT10|\n",
      "+--------------------+------+-----+------+-----------+------------+------+------+------+------+------+------+------+------+------------+------------+----------+----------+----------+----------+---------+------------+-----------+-----------+\n",
      "|1500000US01001020...| 637.0|   01|   001|01001020100|010010201001| 676.0| 649.0| 745.0| 692.0| 636.0| 730.0| 674.0| 693.0|010010201001|010010201001|       1.0|       1.0|       1.0|       1.0|      1.0|         1.0|01001020100|01001020100|\n",
      "|1500000US01001020...| 637.0|   01|   001|01001020100|010010201001| 676.0| 649.0| 745.0| 692.0| 636.0| 730.0| 674.0| 693.0|010010201001|010010201001|       1.0|       1.0|       1.0|       1.0|      1.0|         1.0|01001020100|01001020100|\n",
      "|1500000US01001020...|1171.0|   01|   001|01001020100|010010201002|1224.0|1299.0|1265.0|1153.0|1287.0|1263.0|1267.0|1098.0|010010201002|010010201002|       1.0|       1.0|       1.0|       1.0|      1.0|   0.9987746|01001020100|01001020100|\n",
      "|1500000US01001020...|1171.0|   01|   001|01001020100|010010201002|1224.0|1299.0|1265.0|1153.0|1287.0|1263.0|1267.0|1098.0|010010201002|010010208031|       0.0|       0.0|       0.0|       0.0|      0.0| 0.001225433|01001020803|01001020100|\n",
      "|1500000US01001020...|1383.0|   01|   001|01001020200|010010202001|1289.0|1074.0| 960.0|1020.0| 810.0| 835.0| 706.0| 844.0|010010202001|010010202001|       1.0|       1.0|       1.0|       1.0|      1.0|         1.0|01001020200|01001020200|\n",
      "|1500000US01001020...| 972.0|   01|   001|01001020200|010010202002|1053.0|1082.0|1236.0|1152.0|1218.0|1124.0|1051.0|1166.0|010010202002|010010202002|       1.0|       1.0|       1.0|       1.0|      1.0|  0.99616826|01001020200|01001020200|\n",
      "|1500000US01001020...| 972.0|   01|   001|01001020200|010010202002|1053.0|1082.0|1236.0|1152.0|1218.0|1124.0|1051.0|1166.0|010010202002|010010201001|       0.0|       0.0|       0.0|       0.0|      0.0|0.0038317684|01001020100|01001020200|\n",
      "|1500000US01001020...|2366.0|   01|   001|01001020300|010010203001|2376.0|2143.0|2364.0|2555.0|2641.0|2774.0|2912.0|2685.0|010010203001|010010203001|       1.0|       1.0|       1.0|       1.0|      1.0|         1.0|01001020300|01001020300|\n",
      "|1500000US01001020...| 691.0|   01|   001|01001020300|010010203002| 921.0| 825.0| 772.0| 830.0| 835.0| 733.0| 782.0| 892.0|010010203002|010010203002|       1.0|       1.0|       1.0|       1.0|      1.0|         1.0|01001020300|01001020300|\n",
      "|1500000US01001020...|1088.0|   01|   001|01001020400|010010204001| 970.0| 785.0| 729.0| 651.0| 653.0| 761.0| 720.0| 733.0|010010204001|010010204001|       1.0|       1.0|       1.0|       1.0|      1.0|         1.0|01001020400|01001020400|\n",
      "|1500000US01001020...|2535.0|   01|   001|01001020802|010010208021|2495.0|2677.0|2949.0|3239.0|3099.0|3158.0|  null|  null|010010208021|010010208031|0.28787348|0.26943463|0.28815165|0.29643297|0.2798077|  0.25058144|01001020803|01001020802|\n",
      "|1500000US01001020...|  null|   01|   001|01001020803|010010208031|  null|  null|  null|  null|  null|  null| 811.0|1248.0|010010201002|010010208031|       0.0|       0.0|       0.0|       0.0|      0.0| 0.001225433|01001020803|01001020100|\n",
      "|1500000US01001020...|  null|   01|   001|01001020803|010010208031|  null|  null|  null|  null|  null|  null| 811.0|1248.0|010010208021|010010208031|0.28787348|0.26943463|0.28815165|0.29643297|0.2798077|  0.25058144|01001020803|01001020802|\n",
      "+--------------------+------+-----+------+-----------+------------+------+------+------+------+------+------+------+------+------------+------------+----------+----------+----------+----------+---------+------------+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# CONTINUE TEST: only include blocks in our limited list\n",
    "spark_testing = spark_s3_df.filter(spark_col('BG20').isin(spark_key_list))\n",
    "spark_testing.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8fb2ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE TEST, GROUP BY BG20\n",
    "spark_testing_groups = spark_testing.groupby(\"BG20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e0f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09af3714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>2013</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>BG10</th>\n",
       "      <th>BG20</th>\n",
       "      <th>wt_pop</th>\n",
       "      <th>wt_hu</th>\n",
       "      <th>wt_adult</th>\n",
       "      <th>wt_fam</th>\n",
       "      <th>wt_hh</th>\n",
       "      <th>parea</th>\n",
       "      <th>TRACT20</th>\n",
       "      <th>TRACT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500000US010010202001</td>\n",
       "      <td>1383.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1289.0000</td>\n",
       "      <td>1074.0000</td>\n",
       "      <td>960.0000</td>\n",
       "      <td>1020.0000</td>\n",
       "      <td>810.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>706.0000</td>\n",
       "      <td>844.0000</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>1500000US010179543005</td>\n",
       "      <td>1050.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>017</td>\n",
       "      <td>01017954300</td>\n",
       "      <td>010179543005</td>\n",
       "      <td>1136.0000</td>\n",
       "      <td>1209.0000</td>\n",
       "      <td>1119.0000</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>664.0000</td>\n",
       "      <td>705.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010179543005</td>\n",
       "      <td>010179543003</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>01017954300</td>\n",
       "      <td>01017954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>1500000US010179543005</td>\n",
       "      <td>1050.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>017</td>\n",
       "      <td>01017954300</td>\n",
       "      <td>010179543005</td>\n",
       "      <td>1136.0000</td>\n",
       "      <td>1209.0000</td>\n",
       "      <td>1119.0000</td>\n",
       "      <td>1000.0000</td>\n",
       "      <td>664.0000</td>\n",
       "      <td>705.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010179543005</td>\n",
       "      <td>010179548005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>01017954800</td>\n",
       "      <td>01017954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>1500000US010179544001</td>\n",
       "      <td>817.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>017</td>\n",
       "      <td>01017954400</td>\n",
       "      <td>010179544001</td>\n",
       "      <td>868.0000</td>\n",
       "      <td>906.0000</td>\n",
       "      <td>891.0000</td>\n",
       "      <td>850.0000</td>\n",
       "      <td>822.0000</td>\n",
       "      <td>796.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>010179544001</td>\n",
       "      <td>010179548005</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01017954800</td>\n",
       "      <td>01017954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>1500000US010179548005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>017</td>\n",
       "      <td>01017954800</td>\n",
       "      <td>010179548005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722.0000</td>\n",
       "      <td>728.0000</td>\n",
       "      <td>010179543005</td>\n",
       "      <td>010179548005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>01017954800</td>\n",
       "      <td>01017954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>1500000US010179548005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>017</td>\n",
       "      <td>01017954800</td>\n",
       "      <td>010179548005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>722.0000</td>\n",
       "      <td>728.0000</td>\n",
       "      <td>010179544001</td>\n",
       "      <td>010179548005</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01017954800</td>\n",
       "      <td>01017954400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>948 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    geo_id      2013 state county        tract         block  \\\n",
       "0    1500000US010010201001  637.0000    01    001  01001020100  010010201001   \n",
       "1    1500000US010010201001  637.0000    01    001  01001020100  010010201001   \n",
       "2    1500000US010010201002 1171.0000    01    001  01001020100  010010201002   \n",
       "3    1500000US010010201002 1171.0000    01    001  01001020100  010010201002   \n",
       "4    1500000US010010202001 1383.0000    01    001  01001020200  010010202001   \n",
       "..                     ...       ...   ...    ...          ...           ...   \n",
       "943  1500000US010179543005 1050.0000    01    017  01017954300  010179543005   \n",
       "944  1500000US010179543005 1050.0000    01    017  01017954300  010179543005   \n",
       "945  1500000US010179544001  817.0000    01    017  01017954400  010179544001   \n",
       "961  1500000US010179548005       NaN    01    017  01017954800  010179548005   \n",
       "962  1500000US010179548005       NaN    01    017  01017954800  010179548005   \n",
       "\n",
       "         2014      2015      2016      2017      2018      2019      2020  \\\n",
       "0    676.0000  649.0000  745.0000  692.0000  636.0000  730.0000  674.0000   \n",
       "1    676.0000  649.0000  745.0000  692.0000  636.0000  730.0000  674.0000   \n",
       "2   1224.0000 1299.0000 1265.0000 1153.0000 1287.0000 1263.0000 1267.0000   \n",
       "3   1224.0000 1299.0000 1265.0000 1153.0000 1287.0000 1263.0000 1267.0000   \n",
       "4   1289.0000 1074.0000  960.0000 1020.0000  810.0000  835.0000  706.0000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "943 1136.0000 1209.0000 1119.0000 1000.0000  664.0000  705.0000       NaN   \n",
       "944 1136.0000 1209.0000 1119.0000 1000.0000  664.0000  705.0000       NaN   \n",
       "945  868.0000  906.0000  891.0000  850.0000  822.0000  796.0000       NaN   \n",
       "961       NaN       NaN       NaN       NaN       NaN       NaN  722.0000   \n",
       "962       NaN       NaN       NaN       NaN       NaN       NaN  722.0000   \n",
       "\n",
       "         2021          BG10          BG20  wt_pop  wt_hu  wt_adult  wt_fam  \\\n",
       "0    693.0000  010010201001  010010201001  1.0000 1.0000    1.0000  1.0000   \n",
       "1    693.0000  010010201001  010010201001  1.0000 1.0000    1.0000  1.0000   \n",
       "2   1098.0000  010010201002  010010201002  1.0000 1.0000    1.0000  1.0000   \n",
       "3   1098.0000  010010201002  010010208031  0.0000 0.0000    0.0000  0.0000   \n",
       "4    844.0000  010010202001  010010202001  1.0000 1.0000    1.0000  1.0000   \n",
       "..        ...           ...           ...     ...    ...       ...     ...   \n",
       "943       NaN  010179543005  010179543003  1.0000 1.0000    1.0000  1.0000   \n",
       "944       NaN  010179543005  010179548005  0.0000 0.0000    0.0000  0.0000   \n",
       "945       NaN  010179544001  010179548005  1.0000 1.0000    1.0000  1.0000   \n",
       "961  728.0000  010179543005  010179548005  0.0000 0.0000    0.0000  0.0000   \n",
       "962  728.0000  010179544001  010179548005  1.0000 1.0000    1.0000  1.0000   \n",
       "\n",
       "     wt_hh  parea      TRACT20      TRACT10  \n",
       "0   1.0000 1.0000  01001020100  01001020100  \n",
       "1   1.0000 1.0000  01001020100  01001020100  \n",
       "2   1.0000 0.9988  01001020100  01001020100  \n",
       "3   0.0000 0.0012  01001020803  01001020100  \n",
       "4   1.0000 1.0000  01001020200  01001020200  \n",
       "..     ...    ...          ...          ...  \n",
       "943 1.0000 0.9995  01017954300  01017954300  \n",
       "944 0.0000 0.0005  01017954800  01017954300  \n",
       "945 1.0000 1.0000  01017954800  01017954400  \n",
       "961 0.0000 0.0005  01017954800  01017954300  \n",
       "962 1.0000 1.0000  01017954800  01017954400  \n",
       "\n",
       "[948 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing numbers of blocks\n",
    "stand_testing = pop_pre_st[\n",
    "    pop_pre_st['BG20'].isin(\n",
    "        pop_pre_st['BG20'].unique()[:400])].copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "stand_testing.drop(columns=['name','block group'], inplace=True)\n",
    "\n",
    "spark_df = spark.createDataFrame(stand_testing)\n",
    "spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adf949d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x7f9ad7a49340>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_groups = spark_df.groupby(\"BG20\")\n",
    "spark_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "35bcc394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>2013</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>block</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>BG10</th>\n",
       "      <th>BG20</th>\n",
       "      <th>wt_pop</th>\n",
       "      <th>wt_hu</th>\n",
       "      <th>wt_adult</th>\n",
       "      <th>wt_fam</th>\n",
       "      <th>wt_hh</th>\n",
       "      <th>parea</th>\n",
       "      <th>TRACT20</th>\n",
       "      <th>TRACT10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500000US010010201001</td>\n",
       "      <td>637.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>676.0000</td>\n",
       "      <td>649.0000</td>\n",
       "      <td>745.0000</td>\n",
       "      <td>692.0000</td>\n",
       "      <td>636.0000</td>\n",
       "      <td>730.0000</td>\n",
       "      <td>674.0000</td>\n",
       "      <td>693.0000</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>010010201001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500000US010010201002</td>\n",
       "      <td>1171.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>1224.0000</td>\n",
       "      <td>1299.0000</td>\n",
       "      <td>1265.0000</td>\n",
       "      <td>1153.0000</td>\n",
       "      <td>1287.0000</td>\n",
       "      <td>1263.0000</td>\n",
       "      <td>1267.0000</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>010010201002</td>\n",
       "      <td>010010208031</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>01001020803</td>\n",
       "      <td>01001020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500000US010010202001</td>\n",
       "      <td>1383.0000</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1289.0000</td>\n",
       "      <td>1074.0000</td>\n",
       "      <td>960.0000</td>\n",
       "      <td>1020.0000</td>\n",
       "      <td>810.0000</td>\n",
       "      <td>835.0000</td>\n",
       "      <td>706.0000</td>\n",
       "      <td>844.0000</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>010010202001</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>01001020200</td>\n",
       "      <td>01001020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561867</th>\n",
       "      <td>1500000US721537506012</td>\n",
       "      <td>3437.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>721537506012</td>\n",
       "      <td>2940.0000</td>\n",
       "      <td>2921.0000</td>\n",
       "      <td>2703.0000</td>\n",
       "      <td>2348.0000</td>\n",
       "      <td>2432.0000</td>\n",
       "      <td>2523.0000</td>\n",
       "      <td>1504.0000</td>\n",
       "      <td>1820.0000</td>\n",
       "      <td>721537506012</td>\n",
       "      <td>721537506013</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>72153750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561868</th>\n",
       "      <td>1500000US721537506013</td>\n",
       "      <td>1286.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>721537506013</td>\n",
       "      <td>1612.0000</td>\n",
       "      <td>1367.0000</td>\n",
       "      <td>1195.0000</td>\n",
       "      <td>1292.0000</td>\n",
       "      <td>976.0000</td>\n",
       "      <td>991.0000</td>\n",
       "      <td>1276.0000</td>\n",
       "      <td>1213.0000</td>\n",
       "      <td>721537506013</td>\n",
       "      <td>721537506011</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>72153750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561869</th>\n",
       "      <td>1500000US721537506021</td>\n",
       "      <td>2332.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>721537506021</td>\n",
       "      <td>2351.0000</td>\n",
       "      <td>1994.0000</td>\n",
       "      <td>2005.0000</td>\n",
       "      <td>2055.0000</td>\n",
       "      <td>1707.0000</td>\n",
       "      <td>1577.0000</td>\n",
       "      <td>1410.0000</td>\n",
       "      <td>1295.0000</td>\n",
       "      <td>721537506021</td>\n",
       "      <td>721537506021</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561870</th>\n",
       "      <td>1500000US721537506022</td>\n",
       "      <td>856.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>916.0000</td>\n",
       "      <td>747.0000</td>\n",
       "      <td>736.0000</td>\n",
       "      <td>946.0000</td>\n",
       "      <td>804.0000</td>\n",
       "      <td>648.0000</td>\n",
       "      <td>801.0000</td>\n",
       "      <td>894.0000</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561871</th>\n",
       "      <td>1500000US721537506022</td>\n",
       "      <td>856.0000</td>\n",
       "      <td>72</td>\n",
       "      <td>153</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>916.0000</td>\n",
       "      <td>747.0000</td>\n",
       "      <td>736.0000</td>\n",
       "      <td>946.0000</td>\n",
       "      <td>804.0000</td>\n",
       "      <td>648.0000</td>\n",
       "      <td>801.0000</td>\n",
       "      <td>894.0000</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>721537506022</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>72153750602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561872 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       geo_id      2013 state county        tract  \\\n",
       "0       1500000US010010201001  637.0000    01    001  01001020100   \n",
       "1       1500000US010010201001  637.0000    01    001  01001020100   \n",
       "2       1500000US010010201002 1171.0000    01    001  01001020100   \n",
       "3       1500000US010010201002 1171.0000    01    001  01001020100   \n",
       "4       1500000US010010202001 1383.0000    01    001  01001020200   \n",
       "...                       ...       ...   ...    ...          ...   \n",
       "561867  1500000US721537506012 3437.0000    72    153  72153750601   \n",
       "561868  1500000US721537506013 1286.0000    72    153  72153750601   \n",
       "561869  1500000US721537506021 2332.0000    72    153  72153750602   \n",
       "561870  1500000US721537506022  856.0000    72    153  72153750602   \n",
       "561871  1500000US721537506022  856.0000    72    153  72153750602   \n",
       "\n",
       "               block      2014      2015      2016      2017      2018  \\\n",
       "0       010010201001  676.0000  649.0000  745.0000  692.0000  636.0000   \n",
       "1       010010201001  676.0000  649.0000  745.0000  692.0000  636.0000   \n",
       "2       010010201002 1224.0000 1299.0000 1265.0000 1153.0000 1287.0000   \n",
       "3       010010201002 1224.0000 1299.0000 1265.0000 1153.0000 1287.0000   \n",
       "4       010010202001 1289.0000 1074.0000  960.0000 1020.0000  810.0000   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "561867  721537506012 2940.0000 2921.0000 2703.0000 2348.0000 2432.0000   \n",
       "561868  721537506013 1612.0000 1367.0000 1195.0000 1292.0000  976.0000   \n",
       "561869  721537506021 2351.0000 1994.0000 2005.0000 2055.0000 1707.0000   \n",
       "561870  721537506022  916.0000  747.0000  736.0000  946.0000  804.0000   \n",
       "561871  721537506022  916.0000  747.0000  736.0000  946.0000  804.0000   \n",
       "\n",
       "            2019      2020      2021          BG10          BG20  wt_pop  \\\n",
       "0       730.0000  674.0000  693.0000  010010201001  010010201001  1.0000   \n",
       "1       730.0000  674.0000  693.0000  010010201001  010010201001  1.0000   \n",
       "2      1263.0000 1267.0000 1098.0000  010010201002  010010201002  1.0000   \n",
       "3      1263.0000 1267.0000 1098.0000  010010201002  010010208031  0.0000   \n",
       "4       835.0000  706.0000  844.0000  010010202001  010010202001  1.0000   \n",
       "...          ...       ...       ...           ...           ...     ...   \n",
       "561867 2523.0000 1504.0000 1820.0000  721537506012  721537506013  0.6173   \n",
       "561868  991.0000 1276.0000 1213.0000  721537506013  721537506011  1.0000   \n",
       "561869 1577.0000 1410.0000 1295.0000  721537506021  721537506021  1.0000   \n",
       "561870  648.0000  801.0000  894.0000  721537506022  721537506022  1.0000   \n",
       "561871  648.0000  801.0000  894.0000  721537506022  721537506022  1.0000   \n",
       "\n",
       "        wt_hu  wt_adult  wt_fam  wt_hh  parea      TRACT20      TRACT10  \n",
       "0      1.0000    1.0000  1.0000 1.0000 1.0000  01001020100  01001020100  \n",
       "1      1.0000    1.0000  1.0000 1.0000 1.0000  01001020100  01001020100  \n",
       "2      1.0000    1.0000  1.0000 1.0000 0.9988  01001020100  01001020100  \n",
       "3      0.0000    0.0000  0.0000 0.0000 0.0012  01001020803  01001020100  \n",
       "4      1.0000    1.0000  1.0000 1.0000 1.0000  01001020200  01001020200  \n",
       "...       ...       ...     ...    ...    ...          ...          ...  \n",
       "561867 0.6167    0.6037  0.6202 0.6077 0.8305  72153750601  72153750601  \n",
       "561868 1.0000    1.0000  1.0000 1.0000 1.0000  72153750601  72153750601  \n",
       "561869 1.0000    1.0000  1.0000 1.0000 1.0000  72153750602  72153750602  \n",
       "561870 1.0000    1.0000  1.0000 1.0000 1.0000  72153750602  72153750602  \n",
       "561871 1.0000    1.0000  1.0000 1.0000 1.0000  72153750602  72153750602  \n",
       "\n",
       "[561872 rows x 24 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = wr.s3.read_csv(\n",
    "    \"s3://real-estate-wolff/census-data/block-groups/raw/population_blocks_raw.csv\",\n",
    "    encoding='utf-8',\n",
    "    dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "          'tract':str, 'block':str, 'BG10':str, 'BG20':str,\n",
    "          'TRACT20':str, 'TRACT10':str}\n",
    ")\n",
    "\n",
    "og_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85799835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variable arguments\n",
    "start_year = 2013\n",
    "end_year = 2021\n",
    "og_df = pop_pre_st.copy()\n",
    "weight = \"wt_pop\"\n",
    "\n",
    "def block_standardize_spark(key, pdf):\n",
    "\n",
    "    # Get variables\n",
    "    block = key[0]\n",
    "    years_10_19 = [str(i) for i in range(start_year, 2020)]\n",
    "    years_2020_on = [str(i) for i in range(2020, end_year + 1)]\n",
    "    \n",
    "    # Pandas Dataframe version\n",
    "    df = og_df.copy()\n",
    "\n",
    "    # Step 1: Get a dataframe grouped by BG20\n",
    "    bg20_df = pdf.drop_duplicates().copy()\n",
    "    bg20_df = bg20_df.fillna(0)\n",
    "\n",
    "    # Step 2: Get dot product of 2010-2019 values with the target weight values values\n",
    "    array_10_19 = bg20_df[years_10_19].to_numpy().T\n",
    "    wt_array = bg20_df[weight].to_numpy()\n",
    "    dots = array_10_19.dot(wt_array)\n",
    "\n",
    "    # Step 3: Append standardized 2010-2019 and \n",
    "    # the block's 2020 value to new dictionary\n",
    "    \n",
    "    # This uses a Pandas Dataframe\n",
    "    filtered = df[df['block']==block]\n",
    "    val_20_on = filtered[years_2020_on].iloc[0]\n",
    "    dots = np.append(dots, val_20_on)\n",
    "\n",
    "    # If the 2020 value is 0, then all years\n",
    "    # before then should be 0 also\n",
    "    if val_20_on[0] == 0:\n",
    "        dots = dots * 0\n",
    "        \n",
    "    # Convert to tuple\n",
    "    tuple_dots = tuple(dots)\n",
    "\n",
    "    return pd.DataFrame([key + tuple_dots])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  schema for the key and as many years as we have\n",
    "schema2 = StructType([StructField('geoid_block', StringType(), True)] + \n",
    "                     [StructField(str(i), DoubleType(), True) \n",
    "                      for i in range(start_year, end_year + 1)])\n",
    "\n",
    "# Run standardization function\n",
    "spark_standardized = spark_groups.applyInPandas(\n",
    "    block_standardize_spark, schema=schema2)\n",
    "\n",
    "spark_standardized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b77d6f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------+------+------+------+------+------+------+------+\n",
      "| geoid_block|  2013|  2014|  2015|  2016|  2017|  2018|  2019|  2020|  2021|\n",
      "+------------+------+------+------+------+------+------+------+------+------+\n",
      "|010010201001| 637.0| 676.0| 649.0| 745.0| 692.0| 636.0| 730.0| 674.0| 693.0|\n",
      "|010010201002|1171.0|1224.0|1299.0|1265.0|1153.0|1287.0|1263.0|1267.0|1098.0|\n",
      "|010010202001|1383.0|1289.0|1074.0| 960.0|1020.0| 810.0| 835.0| 706.0| 844.0|\n",
      "|010010202002| 972.0|1053.0|1082.0|1236.0|1152.0|1218.0|1124.0|1051.0|1166.0|\n",
      "|010010203001|2366.0|2376.0|2143.0|2364.0|2555.0|2641.0|2774.0|2912.0|2685.0|\n",
      "+------------+------+------+------+------+------+------+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# TESTING CONTINUED\n",
    "schema3 = StructType([StructField('geoid_block', StringType(), True)] + \n",
    "                     [StructField(str(i), DoubleType(), True) \n",
    "                      for i in range(start_year, end_year + 1)])\n",
    "\n",
    "# Run standardization function\n",
    "spark_test_standardized = spark_testing_groups.applyInPandas(\n",
    "    block_standardize_spark, schema=schema3)\n",
    "\n",
    "spark_test_standardized.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce1866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a99b3cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+------+-----------+------------+-----+-----+-----+-----+-----+-----+-----+-----+------------+------------+------+-----+--------+------+-----+-----+-----------+-----------+\n",
      "|              geo_id| 2013|state|county|      tract|       block| 2014| 2015| 2016| 2017| 2018| 2019| 2020| 2021|        BG10|        BG20|wt_pop|wt_hu|wt_adult|wt_fam|wt_hh|parea|    TRACT20|    TRACT10|\n",
      "+--------------------+-----+-----+------+-----------+------------+-----+-----+-----+-----+-----+-----+-----+-----+------------+------------+------+-----+--------+------+-----+-----+-----------+-----------+\n",
      "|1500000US01001020...|637.0|   01|   001|01001020100|010010201001|676.0|649.0|745.0|692.0|636.0|730.0|674.0|693.0|010010201001|010010201001|   1.0|  1.0|     1.0|   1.0|  1.0|  1.0|01001020100|01001020100|\n",
      "|1500000US01001020...|637.0|   01|   001|01001020100|010010201001|676.0|649.0|745.0|692.0|636.0|730.0|674.0|693.0|010010201001|010010201001|   1.0|  1.0|     1.0|   1.0|  1.0|  1.0|01001020100|01001020100|\n",
      "+--------------------+-----+-----+------+-----------+------------+-----+-----+-----+-----+-----+-----+-----+-----+------------+------------+------+-----+--------+------+-----+-----+-----------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_s3_df.filter(spark_s3_df['block']=='010010201001').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2c2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4da25a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save spark dataframe to csv\n",
    "spark_standardized.toPandas().to_csv(\n",
    "    \"datasets/cleaned_census_api_files/raw/population_spark_standardized_raw.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529f498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "826d299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://real-estate-wolff/census-data/block-groups/standardized/population_blocks_standardized.csv'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make block-group s3 path\n",
    "block_group_s3_path = \"s3://real-estate-wolff/census-data/block-groups/standardized\"\n",
    "filename = \"population_blocks_standardized.csv\"\n",
    "s3_path = f\"{block_group_s3_path}/{filename}\"\n",
    "\n",
    "# Save to s3\n",
    "# wr.s3.to_csv(pop_pre_st.toPandas(), s3_path, index=False)\n",
    "wr.s3.to_csv(spark_test_standardized.toPandas(), s3_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073aefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ce89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b36e5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4ec03",
   "metadata": {},
   "source": [
    "### Final dataframe clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d527fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_standardized_df_1 = pd.read_csv('datasets/cleaned_census_api_files/raw/population_standardized_raw.csv',\n",
    "                                  encoding='utf-8',\n",
    "                                 dtype={'geoid_block':str})\n",
    "\n",
    "# Run statistics function to get ratio and z-score\n",
    "pop_standardized_df_1 = get_statistics(\n",
    "    pop_standardized_df_1, begin_year=2013, end_year=2021)\n",
    "\n",
    "# Add columns for state,county, and tract, and make sums for census tracts\n",
    "pop_standardized_df_2 = specify_geographies(pop_standardized_df_1, 2013, 2021)\n",
    "display(pop_standardized_df_2.head(1))\n",
    "\n",
    "pop_standardized_df_2.to_csv('datasets/cleaned_census_api_files/standardized/population_standardized.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)\n",
    "\n",
    "# Plot zscores to check for anomalies\n",
    "plot_zscores(pop_standardized_df_2['z_score'], 'Population')\n",
    "\n",
    "# Create the shapefiles for block groups and tracts\n",
    "pop_tract_geo = create_and_save_geo_files(dataframe=pop_standardized_df_2, \n",
    "                                          name='population',\n",
    "                                          begin_year=2013, \n",
    "                                          end_year=2021)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a300f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9451dc90",
   "metadata": {},
   "source": [
    "### Group Tracts By City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef11f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Use the below function and incorporate it into the main\n",
    "##### cencus helper functions. \n",
    "\n",
    "def group_tracts_by_city(tract_gdf, city_name, state_name):\n",
    "    \"\"\"\n",
    "    Group tracts by a given city and save them as\n",
    "    an individual dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "        tract_gdf (GeoDataFrame): The geodataframe\n",
    "            you want to split by city.\n",
    "        city_name (str): Name of city.\n",
    "        state_name (str): Name of state.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the city shapefile\n",
    "    city_boundaries = gp.read_file(\n",
    "        \"datasets/census_original_files/cities_2020/all_cities_2020/all_tracts_2020.shp\")\n",
    "    \n",
    "    # Filter by city name and state\n",
    "    \n",
    "    # Make copy\n",
    "    df = tract_gdf.copy()\n",
    "    \n",
    "    ### Below is an algorithm to only keep tracts\n",
    "    ### that are within 50% or more of a city's boundary\n",
    "    \n",
    "    # Step 1: Calculate area of each tract\n",
    "    df['tract_area'] = df.area\n",
    "    \n",
    "    # Step 2: Overlay the city boundaries over the tracts\n",
    "    df_2 = df.overlay(city_boundaries, how=\"intersect\")\n",
    "    \n",
    "    display(df_2)\n",
    "    \n",
    "    # Step 3: Calculate new areas\n",
    "    df_2['area_']\n",
    "    \n",
    "group_tracts_by_city(pop_tract_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6972825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_tract_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83614fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporary code - can be deleted once file is created\n",
    "\n",
    "# Goal: Create csv that matches states to FIPS codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279dd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8887567",
   "metadata": {},
   "source": [
    "End of standardizing and merging population\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02513d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a99c419",
   "metadata": {},
   "source": [
    "## Median Gross Rent\n",
    "\n",
    "Estimated Median of bin values = ð‘™ + (ð‘›/2 âˆ’ ð¹)/ð‘“ â‹… ð‘¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5a880",
   "metadata": {},
   "source": [
    "#### Below is their \"Median Value.\" Once we standardize, compare the values to this table below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6208082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Start list\n",
    "# df_list = []\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# # Start session\n",
    "# session = Session()\n",
    "\n",
    "# # Define our API variable\n",
    "# # It's within a dictionary because some variables\n",
    "# # can change names from year to year (but not all)\n",
    "# census_code_dict = {\n",
    "#     2013: 'B25064_001E',\n",
    "#     2014: 'B25064_001E',\n",
    "#     2015: 'B25064_001E', # No change in code number this year\n",
    "#     2016: 'B25064_001E',\n",
    "#     2017: 'B25064_001E',\n",
    "#     2018: 'B25064_001E',\n",
    "#     2019: 'B25064_001E',\n",
    "#     2020: 'B25064_001E',\n",
    "#     2021: 'B25064_001E'\n",
    "# }\n",
    "\n",
    "# census_code_meaning='median_rent_2013_2021_blocks'\n",
    "\n",
    "# # Run the API call\n",
    "# asyncio.run(url_to_dataframe_async_owners(2013, 2021, \n",
    "#                                           fifty_states_list,\n",
    "#                                           census_code_dict,\n",
    "#                                           df_list=df_list,\n",
    "#                                           census_code_meaning=census_code_meaning,\n",
    "#                                          get_blocks=True,\n",
    "#                                          ))\n",
    "\n",
    "# # Get merged dataframe\n",
    "# median_rent_raw = final_data_prep(df_list, census_code_meaning, blocks=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fcd48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_rent_raw = pd.read_csv('datasets/cleaned_census_api_files/raw/median_rent_2013_2021_blocks_raw.csv',\n",
    "                                   encoding='utf-8',\n",
    "                                   dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "                                          'tract':str, 'block group':str, 'block':str})\n",
    "median_rent_raw['block'] = median_rent_raw['geo_id'].apply(lambda x: str(x)[-12:])\n",
    "\n",
    "spot_check(median_rent_raw, 2013, 2021)\n",
    "\n",
    "median_rent_raw.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17166bc5",
   "metadata": {},
   "source": [
    "#### Get Gross Rent for each category, then combine them! Try to get all codes for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Gross Rent Code for each year\n",
    "rent_code_list = []\n",
    "for i in range(3, 27):\n",
    "    if i < 10:\n",
    "        i = '0' + str(i)\n",
    "    rent_code_list.append(f'B25063_0{i}E')\n",
    "    \n",
    "rent_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328b3e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Start list\n",
    "# df_list = []\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# # Start session\n",
    "# session = Session()\n",
    "\n",
    "# # Define our API variable\n",
    "# # It's within a dictionary because some variables\n",
    "# # can change names from year to year (but not all)\n",
    "# rent_code_list = []\n",
    "# for i in range(3, 27):\n",
    "#     if i < 10:\n",
    "#         i = '0' + str(i)\n",
    "#     rent_code_list.append(f'B25063_0{i}E')\n",
    "    \n",
    "# census_code_dict = {\n",
    "#     2013: rent_code_list[:-3],\n",
    "#     2014: rent_code_list[:-3],\n",
    "#     2015: rent_code_list, \n",
    "#     2016: rent_code_list,\n",
    "#     2017: rent_code_list,\n",
    "#     2018: rent_code_list,\n",
    "#     2019: rent_code_list,\n",
    "#     2020: rent_code_list,\n",
    "#     2021: rent_code_list\n",
    "# }\n",
    "\n",
    "# code_name_dict = {\n",
    "#     'B25063_003E': 'rent_less_than_100',\n",
    "#     'B25063_004E': 'rent_100_to_149',\n",
    "#     'B25063_005E': 'rent_150_to_199',\n",
    "#     'B25063_006E': 'rent_200_to_249',\n",
    "#     'B25063_007E': 'rent_250_to_299',\n",
    "#     'B25063_008E': 'rent_300_to_349',\n",
    "#     'B25063_009E': 'rent_350_to_399',\n",
    "#     'B25063_010E': 'rent_400_to_449',\n",
    "#     'B25063_011E': 'rent_450_to_499',\n",
    "#     'B25063_012E': 'rent_500_to_549',\n",
    "#     'B25063_013E': 'rent_550_to_599',\n",
    "#     'B25063_014E': 'rent_600_to_649',\n",
    "#     'B25063_015E': 'rent_650_to_699',\n",
    "#     'B25063_016E': 'rent_700_to_749',\n",
    "#     'B25063_017E': 'rent_750_to_799',\n",
    "#     'B25063_018E': 'rent_800_to_899',\n",
    "#     'B25063_019E': 'rent_900_to_999',\n",
    "#     'B25063_020E': 'rent_1000_to_1249',\n",
    "#     'B25063_021E': 'rent_1250_to_1449',\n",
    "#     'B25063_022E': 'rent_1500_to_1999',\n",
    "#     'B25063_023E': 'rent_2000_to_2499',\n",
    "#     'B25063_024E': 'rent_2500_to_2999',\n",
    "#     'B25063_025E': 'rent_3000_to_3499',\n",
    "#     'B25063_026E': 'rent_3500_or_more',\n",
    "# }\n",
    "\n",
    "# census_code_meaning='rent_distribution_blocks'\n",
    "\n",
    "# # Run the API call\n",
    "# asyncio.run(url_to_dataframe_async_owners(2013, 2021, \n",
    "#                                           fifty_states_list,\n",
    "#                                           census_code_dict,\n",
    "#                                           df_list=df_list,\n",
    "#                                           census_code_meaning=census_code_meaning,\n",
    "#                                          get_blocks=True,\n",
    "#                                          multi_code=True,\n",
    "#                                          code_name_dict=code_name_dict\n",
    "#                                          ))\n",
    "\n",
    "# # Get merged dataframe\n",
    "# rent_distribution = final_data_prep(df_list, census_code_meaning, blocks=True)\n",
    "# rent_dist_pre_st = merge_with_crosswalk(rent_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf619a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom spot checking\n",
    "# print(\"How many states:\", len(rent_dist['state'].value_counts()), \"\\n\")\n",
    "\n",
    "# for code in code_name_dict:\n",
    "    \n",
    "#     name = code_name_dict[code]\n",
    "    \n",
    "#     print(f\"Values for {name}\")\n",
    "    \n",
    "#     if (name != 'rent_2500_to_2999') and (name != 'rent_3000_to_3499') and (name != 'rent_3500_or_more'):\n",
    "        \n",
    "#         # Check for null values\n",
    "#         for i in range(2013, 2021):\n",
    "#             print(f\"{name} Null values in {i}:\", rent_dist[rent_dist[f'{i}_{name}'].isnull()].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check for null values in multiple years\n",
    "#         for i in range(2013, 2020):\n",
    "#             print(f\"2020 and {i} {name} null values:\", rent_dist[(rent_dist[f'2020_{name}'].isnull()) & (rent_dist[f'{i}_{name}'].isnull())].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check stats\n",
    "#         for i in range(2013, 2021):\n",
    "#             print(f\"{name} Stats for year {i}:\\n\", rent_dist[f'{i}_{name}'].describe(), \"\\n\")\n",
    "            \n",
    "#     else:\n",
    "        \n",
    "#         # Check for null values\n",
    "#         for i in range(2015, 2021):\n",
    "#             print(f\"{name} Null values in {i}:\", rent_dist[rent_dist[f'{i}_{name}'].isnull()].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check for null values in multiple years\n",
    "#         for i in range(2015, 2020):\n",
    "#             print(f\"2020 and {i} {name} null values:\", rent_dist[(rent_dist[f'2020_{name}'].isnull()) & (rent_dist[f'{i}_{name}'].isnull())].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check stats\n",
    "#         for i in range(2015, 2021):\n",
    "#             print(f\"{name} Stats for year {i}:\\n\", rent_dist[f'{i}_{name}'].describe(), \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_dist = pd.read_csv('datasets/cleaned_census_api_files/raw/rent_distribution_blocks_raw.csv',\n",
    "                        encoding='utf-8',\n",
    "                       dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "                                          'tract':str, 'block group':str, 'block':str})\n",
    "rent_dist_pre_st = merge_with_crosswalk(rent_dist)\n",
    "rent_dist_pre_st.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7d92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_standardize_medians_3(bg20_df,\n",
    "                            og_df,\n",
    "                            year_start,\n",
    "                            year_end,\n",
    "                            weight,\n",
    "                            code_name_dict_2013_2014=False,\n",
    "                            code_name_dict_2015_2021=False,\n",
    "                            code_name_dict_all=False):\n",
    "\n",
    "    \"\"\"\n",
    "    WARNING: This function alone takes a few seconds to complete\n",
    "    per block group, but to standard all 242,333 block groups\n",
    "    can take many, many hours to run.\n",
    "    It would be wise to run this function on any type of\n",
    "    parrallel processing, such as using Dask, or a GPU,\n",
    "    or parrallelized cloud computing, as there is no\n",
    "    serialization (the block groups can be standardized\n",
    "    in no particular order).\n",
    "    \n",
    "    This function standardizes all block group rows. It \n",
    "    should be called in a loop or vectorized if possible,\n",
    "    such as the example below. (Note, the example below\n",
    "    may not be the most efficient way to loop through\n",
    "    or vectorize the block groups.)\n",
    "    \n",
    "    ```\n",
    "    # Loop through all population block groups\n",
    "    # and standardize them\n",
    "    pop_dictionary = {}\n",
    "    array2 = pop_pre_st['BG20'].unique()\n",
    "    [block_standardize(\n",
    "            x, \n",
    "            pop_dict=pop_dictionary, \n",
    "            og_df=pop_pre_st) \n",
    "        for x in array2]\n",
    "    ```\n",
    "    \n",
    "    Parameters:\n",
    "        tuple (tuple): A tuple containing the below.\n",
    "            block (str): The block_group to group by.\n",
    "            og_df (DataFrame): The dataframe we are \n",
    "                standardizing from.\n",
    "            year_start (int): Which year to start from.\n",
    "            year_end (int): Which year to end from.\n",
    "            weight (str): Which weight to use (such as \n",
    "                'wt_pop' pr 'wt_hh').\n",
    "    \n",
    "    Returns:\n",
    "        None. However, it appends the standardized values\n",
    "            per block group to a pre-defined dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    block = bg20_df['BG20'].iloc[0]\n",
    "        \n",
    "    # Step 1: Get a dataframe grouped by BG20\n",
    "    bg20_df = bg20_df.drop_duplicates()\n",
    "    bg20_df = bg20_df.fillna(0)\n",
    "    filtered = og_df[og_df['block']==block].copy().drop_duplicates()\n",
    "    \n",
    "    # make sure the final dict is in the form of {block : dots}\n",
    "    return_array = np.array([])\n",
    "    \n",
    "    if code_name_dict_all == False:\n",
    "    \n",
    "        # Step 2: Loop through the code names that 2013 and 2014 are guaranteed to have\n",
    "        for code in code_name_dict_2013_2014:\n",
    "\n",
    "            rent_category = code_name_dict_2013_2014[code]\n",
    "            years_13_19 = [f\"{i}_{rent_category}\" for i in range(2013, 2020)]\n",
    "\n",
    "            # Step 3: Get dot product of 2013-2019 values with the target weight values values\n",
    "            array_13_19 = bg20_df[years_13_19].to_numpy().T\n",
    "            wt_array = bg20_df[weight].to_numpy()\n",
    "            dots = array_13_19.dot(wt_array)\n",
    "\n",
    "            # Step 4: Append standardized 2013-2019 and \n",
    "            # the block's 2020+ values to new dictionary\n",
    "            val_20s = filtered[[\n",
    "                f\"{i}_{rent_category}\" for i in \n",
    "                range(2020, year_end + 1)]].iloc[0].to_numpy()\n",
    "            \n",
    "            # If the 2020 value is 0, then all years\n",
    "            # before then should be 0 also\n",
    "            if val_20s[0] == 0:\n",
    "                dots = dots * 0\n",
    "\n",
    "            # val_20 = filtered[f'2020_{rent_category}'].iloc[0]\n",
    "            \n",
    "            # Finalize the append\n",
    "            dots = np.append(dots, val_20s)\n",
    "\n",
    "            # Save a copy of the array\n",
    "            set_dots = dots.copy()\n",
    "\n",
    "            # Update return_dictionary\n",
    "            return_array = np.append(return_array, set_dots)\n",
    "\n",
    "        # Step 2: Loop through the code names that 2013 and 2014 won't have\n",
    "        for code in code_name_dict_2015_2021:\n",
    "\n",
    "            rent_category = code_name_dict_2015_2021[code]\n",
    "            years_15_19 = [f\"{i}_{rent_category}\" for i in range(2015, 2020)]\n",
    "\n",
    "            # Step 3: Get dot product of 2015-2019 values with the target weight values values\n",
    "            array_15_19 = bg20_df[years_15_19].to_numpy().T\n",
    "            wt_array = bg20_df[weight].to_numpy()\n",
    "            dots = array_15_19.dot(wt_array)\n",
    "            \n",
    "            # Step 4: Append standardized 2013-2019 and \n",
    "            # the block's 2020+ values to new dictionary\n",
    "            val_20s = filtered[[\n",
    "                f\"{i}_{rent_category}\" for i in \n",
    "                range(2020, year_end + 1)]].iloc[0].to_numpy()\n",
    "            \n",
    "            # If the 2020 value is 0, then all years\n",
    "            # before then should be 0 also\n",
    "            if val_20s[0] == 0:\n",
    "                dots = dots * 0\n",
    "            \n",
    "            # Finalize the append\n",
    "            dots = np.append(dots, val_20s)\n",
    "\n",
    "            # Save a copy of the array\n",
    "            set_dots = dots.copy()\n",
    "\n",
    "            # Update return_dictionary\n",
    "            return_array = np.append(return_array, set_dots)\n",
    "            \n",
    "    else: # if code_name_dict_all exists\n",
    "        for code in code_name_dict_all:\n",
    "\n",
    "            rent_category = code_name_dict_all[code]\n",
    "            years_13_19 = [f\"{i}_{rent_category}\" for i in range(2013, 2020)]\n",
    "\n",
    "            # Step 3: Get dot product of 2010-2019 values with the target weight values values\n",
    "            array_13_19 = bg20_df[years_13_19].to_numpy().T\n",
    "            wt_array = bg20_df[weight].to_numpy()\n",
    "            dots = array_13_19.dot(wt_array)\n",
    "            \n",
    "            # Step 4: Append standardized 2013-2019 and \n",
    "            # the block's 2020+ values to new dictionary\n",
    "            val_20s = filtered[[\n",
    "                f\"{i}_{rent_category}\" for i in \n",
    "                range(2020, year_end + 1)]].iloc[0].to_numpy()\n",
    "            \n",
    "            # If the 2020 value is 0, then all years\n",
    "            # before then should be 0 also\n",
    "            if val_20s[0] == 0:\n",
    "                dots = dots * 0\n",
    "\n",
    "            # Finalize the append\n",
    "            dots = np.append(dots, val_20s)\n",
    "\n",
    "            # Save a copy of the array\n",
    "            set_dots = dots.copy()\n",
    "\n",
    "            # Update return_dictionary\n",
    "            return_array = np.append(return_array, set_dots)\n",
    "        \n",
    "    return {block : return_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b9a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using list comprehension\n",
    "\n",
    "begin_year = 2013\n",
    "end_year = 2021\n",
    "\n",
    "my_groups = rent_dist_pre_st.groupby('BG20')\n",
    "keys = list(my_groups.groups.keys())\n",
    "\n",
    "code_name_dict_2013_2014 = {\n",
    "    'B25063_003E': 'rent_less_than_100',\n",
    "    'B25063_004E': 'rent_100_to_149',\n",
    "    'B25063_005E': 'rent_150_to_199',\n",
    "    'B25063_006E': 'rent_200_to_249',\n",
    "    'B25063_007E': 'rent_250_to_299',\n",
    "    'B25063_008E': 'rent_300_to_349',\n",
    "    'B25063_009E': 'rent_350_to_399',\n",
    "    'B25063_010E': 'rent_400_to_449',\n",
    "    'B25063_011E': 'rent_450_to_499',\n",
    "    'B25063_012E': 'rent_500_to_549',\n",
    "    'B25063_013E': 'rent_550_to_599',\n",
    "    'B25063_014E': 'rent_600_to_649',\n",
    "    'B25063_015E': 'rent_650_to_699',\n",
    "    'B25063_016E': 'rent_700_to_749',\n",
    "    'B25063_017E': 'rent_750_to_799',\n",
    "    'B25063_018E': 'rent_800_to_899',\n",
    "    'B25063_019E': 'rent_900_to_999',\n",
    "    'B25063_020E': 'rent_1000_to_1249',\n",
    "    'B25063_021E': 'rent_1250_to_1449',\n",
    "    'B25063_022E': 'rent_1500_to_1999',\n",
    "    'B25063_023E': 'rent_2000_to_2499'\n",
    "}\n",
    "\n",
    "code_name_dict_2015_2021 = {\n",
    "    'B25063_024E': 'rent_2500_to_2999',\n",
    "    'B25063_025E': 'rent_3000_to_3499',\n",
    "    'B25063_026E': 'rent_3500_or_more'\n",
    "}\n",
    "\n",
    "dict2 = {}\n",
    "dict3 = [block_standardize_medians_3(my_groups.get_group(keys[i]), \n",
    "                                rent_dist_pre_st, \n",
    "                                begin_year, \n",
    "                                end_year, \n",
    "                                'wt_hh', \n",
    "                                code_name_dict_2013_2014=code_name_dict_2013_2014, \n",
    "                                code_name_dict_2015_2021=code_name_dict_2015_2021)\n",
    "        for i in range(len(keys))\n",
    "       ]\n",
    "\n",
    "\n",
    "for d in dict3:\n",
    "    dict2.update(d)\n",
    "\n",
    "column_list = []\n",
    "for code in code_name_dict_2013_2014:\n",
    "    for i in range(begin_year, end_year + 1):\n",
    "        column_list.append(f'{i}_{code_name_dict_2013_2014[code]}')\n",
    "for code in code_name_dict_2015_2021:\n",
    "    for i in range(begin_year, end_year + 1):\n",
    "        column_list.append(f'{i}_{code_name_dict_2015_2021[code]}')\n",
    "\n",
    "gross_rent_df = (pd.DataFrame.from_dict(dict2, \n",
    "                   orient='index', columns=column_list)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'index':'geoid_block'}))\n",
    "\n",
    "gross_rent_df.to_csv('datasets/cleaned_census_api_files/raw/gross_rent_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)\n",
    "\n",
    "gross_rent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d473ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_df.to_csv('datasets/cleaned_census_api_files/raw/gross_rent_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934415",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_df = pd.read_csv('datasets/cleaned_census_api_files/raw/gross_rent_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          dtype={'geoid_block':str})\n",
    "\n",
    "# Make geoid_block the index\n",
    "gross_rent_df.set_index('geoid_block', inplace=True)\n",
    "gross_rent_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67f790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088606c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee35242",
   "metadata": {},
   "source": [
    "### Once I have the gross rents standardized, calculate the median value for each year using frequency tables\n",
    "\n",
    "Estimated Median of bin values = ð‘™ + (ð‘›/2 âˆ’ ð¹)/ð‘“ â‹… ð‘¤\n",
    "\n",
    "where ð‘™ is the lower border of the median group, ð¹ is the cumulative frequency up to the median group, ð‘“ is the frequency of the median group, ð‘¤ is the width of the median group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29f08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEPS TO ESTIMATE MEDIAN VALUE\n",
    "def estimate_median(series, year, keyword):\n",
    "    \"\"\"\n",
    "    Estimate the median for a given year.\n",
    "    \"\"\"\n",
    "    s = series.copy()\n",
    "    year = str(year)\n",
    "#     print(series.name)\n",
    "    \n",
    "    # Gather all variables for the equation\n",
    "    non_zero_series = s[s != 0]\n",
    "    n = non_zero_series.sum()\n",
    "    \n",
    "    if len(non_zero_series) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Find median interval\n",
    "    median_n = n/2\n",
    "\n",
    "    series_dict = non_zero_series.to_dict()\n",
    "    key_list = list(series_dict.keys())\n",
    "    count = 0\n",
    "    interval = ''\n",
    "    interval_backup = None\n",
    "    i = 0\n",
    "    while i < len(key_list):\n",
    "        key = key_list[i]\n",
    "        if count < median_n:\n",
    "            interval = key\n",
    "            count += series_dict[key]\n",
    "            if count > median_n:\n",
    "                F = count - series_dict[key]\n",
    "        elif count == median_n:\n",
    "            F = count\n",
    "            interval_backup = key_list[i]\n",
    "            i = len(key_list)\n",
    "        else:\n",
    "            pass\n",
    "        i += 1\n",
    "        \n",
    "    f = series_dict[interval]\n",
    "        \n",
    "    # Get l, the lower bound\n",
    "    interval_bound = interval.replace(f'{year}_{keyword}_','')\n",
    "    l = int(re.sub(r'_to_\\d+|less_than_|_or_more','',interval_bound))\n",
    "    \n",
    "    # Get higher bound\n",
    "    h = int(re.sub(r'\\d+_to_|less_than_|_or_more','',interval_bound))\n",
    "\n",
    "    # Get width\n",
    "    w = h - l\n",
    "    \n",
    "    # Calculate almost_median\n",
    "    almost_median = (((n/2) - F)/f)*w\n",
    "    \n",
    "    # Check if there is no \"median interval\"\n",
    "    if (almost_median == 0) & (interval_backup is not None):\n",
    "        \n",
    "        # Get l, the lower bound\n",
    "        interval_higher_bound = interval_backup.replace(f'{year}_{keyword}_','')\n",
    "        l_higher = int(re.sub(r'_to_\\d+|less_than_|_or_more','',\n",
    "                              interval_higher_bound))\n",
    "\n",
    "        # Get higher bound\n",
    "        h_higher = int(re.sub(r'\\d+_to_|less_than_|_or_more','',interval_higher_bound))\n",
    "\n",
    "        # Calculate average of lower-lower bound and higher-higher bound\n",
    "        split_intervals_median = (l + h_higher)/2\n",
    "        \n",
    "        # This is our median\n",
    "        return split_intervals_median\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        # estimate median\n",
    "        estimated_median = l + almost_median\n",
    "\n",
    "        return estimated_median\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians = gross_rent_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357aee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate gross rent for every year\n",
    "for i in range(2013, 2021):\n",
    "    columns_year = gross_rent_df.columns[gross_rent_df.columns.str.contains(str(i))]\n",
    "    gross_rent_medians[f'{i}_median'] = gross_rent_df[columns_year].apply(\n",
    "        lambda x: estimate_median(x, str(i), 'rent'),\n",
    "        axis=1\n",
    "    )\n",
    "gross_rent_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c000484",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians.to_csv('datasets/cleaned_census_api_files/raw/gross_rent_medians_raw.csv',\n",
    "                          encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians = pd.read_csv('datasets/cleaned_census_api_files/raw/gross_rent_medians_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          dtype={'geoid_block':str}\n",
    "                                )\n",
    "gross_rent_medians.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians = gross_rent_medians[['geoid_block','2013_median','2014_median','2015_median',\n",
    "                                        '2016_median','2017_median','2018_median',\n",
    "                                        '2019_median','2020_median']]\n",
    "gross_rent_medians.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41dce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loop that goes through each year backyards, \n",
    "# and linearly interpolate values between 0 values \n",
    "# (to show one consistent line on a grpah between two points spearated by \"0\")\n",
    "def linearly_interpolate(dataframe, \n",
    "                         grouping='block'):\n",
    "    \"\"\"Linearly interpolate NaN values.\"\"\"\n",
    "    df = copy.deepcopy(dataframe)\n",
    "    df = df.replace(0, np.nan)\n",
    "    df = df.set_index(f'geoid_{grouping}')\n",
    "    df = df.interpolate(axis=1).reset_index()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e582cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_interpolated = linearly_interpolate(gross_rent_medians)\n",
    "median_rent_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286212d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### Now get the median tract values\n",
    "def get_tract_median_values(dataframe):\n",
    "    \"Sum blocks for tracts then calculate each year's median.\"\n",
    "    \n",
    "    df = copy.deepcopy(dataframe)\n",
    "    if 'geoid_block' not in df.columns:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    df['geoid_tract'] = df['geoid_block'].apply(lambda x: str(x)[:-1])\n",
    "    df['state'] = df['geoid_block'].apply(lambda x: str(x)[0:2])\n",
    "    df['county'] = df['geoid_block'].apply(lambda x: str(x)[2:5])\n",
    "    \n",
    "    # Calculate gross rent for every year\n",
    "    for i in range(2013, 2021):\n",
    "        str_year = str(i)\n",
    "        columns_year = df.columns[df.columns.str.contains(str_year)]\n",
    "        for col in columns_year:\n",
    "            main_name = col.replace(f'{i}_rent_','')\n",
    "            df[f'{i}_tract_rent_{main_name}'] = df.groupby('geoid_tract')[f'{col}'].transform('sum')\n",
    "        tracts_year = df.columns[df.columns.str.contains(f'{str_year}_tract')]\n",
    "        df[f'{i}_tract_median'] = df[tracts_year].apply(\n",
    "            lambda x: estimate_median(x, str(i), 'tract_rent'),\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "gross_rent_tract = get_tract_median_values(gross_rent_df)\n",
    "gross_rent_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74516d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_tract_2 = gross_rent_tract[['geoid_tract',\n",
    "                                       '2013_tract_median','2014_tract_median','2015_tract_median',\n",
    "                                        '2016_tract_median','2017_tract_median','2018_tract_median',\n",
    "                                        '2019_tract_median','2020_tract_median']].drop_duplicates()\n",
    "gross_rent_tract_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6737d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_tract_rent_interpolated = linearly_interpolate(gross_rent_tract_2, grouping='tract')\n",
    "median_tract_rent_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_interpolated['geoid_tract'] = median_rent_interpolated['geoid_block'].apply(\n",
    "    lambda x: str(x)[:-1])\n",
    "\n",
    "median_rent_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all = pd.merge(median_rent_interpolated,\n",
    "                           median_tract_rent_interpolated,\n",
    "                           left_on=\"geoid_tract\",\n",
    "                           right_on=\"geoid_tract\",\n",
    "                           how='inner')\n",
    "\n",
    "median_rent_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2021):\n",
    "    median_rent_all.rename(columns={f'{year}_median': f'{year}_block_median'}, inplace=True)\n",
    "    \n",
    "median_rent_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9be15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all['state'] = median_rent_all['geoid_block'].apply(lambda x: str(x)[0:2])\n",
    "median_rent_all['county'] = median_rent_all['geoid_block'].apply(lambda x: str(x)[2:5])\n",
    "median_rent_all['tract'] = median_rent_all['geoid_block'].apply(lambda x: str(x)[5:11])\n",
    "\n",
    "median_rent_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85cd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all.to_csv('datasets/cleaned_census_api_files/standardized/median_rent_standardized.csv',\n",
    "                       encoding='utf-8',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all = pd.read_csv('datasets/cleaned_census_api_files/standardized/median_rent_standardized.csv',\n",
    "                               encoding='utf-8',\n",
    "                             dtype={'geoid_block':str, 'geoid_tract':str})\n",
    "\n",
    "median_rent_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb470ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Once I have the interpolated median tract values, merge with block level,\n",
    "# Save, then run create_and_save_geo_files() function on it\n",
    "\n",
    "# Create the shapefiles for block groups and tracts\n",
    "median_rent_block_geo, median_rent_tract_geo = create_and_save_geo_files(dataframe=median_rent_all, \n",
    "                                                          name='median_rent',\n",
    "                                                          keyword='median',\n",
    "                                                          begin_year=2013, \n",
    "                                                          end_year=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_block_geo\n",
    "median_rent_tract_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f6e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6a9cb5",
   "metadata": {},
   "source": [
    "### End of getting data at the Tract level\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfeacc",
   "metadata": {},
   "source": [
    "# Get data at the MSA level\n",
    "\n",
    "We will get the following:\n",
    "1. Median Income\n",
    "2. Median Unit Price\n",
    "3. Median Rent\n",
    "\n",
    "using the ACS 1-Year survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c103c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end year for all MSAs\n",
    "end_year=2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0268c",
   "metadata": {},
   "source": [
    "### Get Median Income at the MSA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331b095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_income_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B19013_001E\",\n",
    "    census_code_meaning=\"median_income_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "median_income_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a2fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4902f25",
   "metadata": {},
   "source": [
    "### Get Median Unit Value at the MSA Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff1dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_price_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B25077_001E\",\n",
    "    census_code_meaning=\"median_price_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "median_price_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d0f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e59a5c9",
   "metadata": {},
   "source": [
    "### Get Median Rent at the MSA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a878dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_rent_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B25058_001E\",\n",
    "    census_code_meaning=\"median_rent_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "median_rent_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49140d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "812a5a48",
   "metadata": {},
   "source": [
    "### Get Total Units at the MSA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f80a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_units_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B25001_001E\",\n",
    "    census_code_meaning=\"total_units_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "total_units_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da670033",
   "metadata": {},
   "source": [
    "### Create Rent-to-Price Ratio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388e383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "for i in range(2010, end_year + 1):\n",
    "    median_rent_msa.rename(columns={f\"{i}\":f\"{i}_rent\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(2010, end_year + 1):\n",
    "    median_price_msa.rename(columns={f\"{i}\":f\"{i}_price\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "rent_to_price = median_rent_msa.merge(\n",
    "    median_price_msa, how='inner', \n",
    "    on=['msa_code','msa_name'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(2010, end_year + 1):\n",
    "    rent_to_price[f'{i}'] = rent_to_price[f\"{i}_rent\"]/rent_to_price[f\"{i}_price\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    rent_to_price.drop(columns=[f'{i}_rent',f'{i}_price'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "rent_to_price.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/msa_data/rent_price_ratio_msa.csv\", \n",
    "    index=False)\n",
    "\n",
    "rent_to_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10444a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c548b35",
   "metadata": {},
   "source": [
    "### Create Jobs per Unit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b69fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in jobs\n",
    "jobs = pd.read_csv('datasets/bls/raw/most_recent_bls_data.csv',\n",
    "                   dtype={'msa_code':str, 'state_code':str})\n",
    "\n",
    "# Make sure the date column is in datetime format\n",
    "jobs['date'] = pd.to_datetime(jobs['date'])\n",
    "\n",
    "# Replace NECTA Division\n",
    "jobs['msa_name'] = jobs['msa_name'].apply(lambda x: x.replace(\" NECTA Division\",\"\"))\n",
    "jobs['msa_name'] = jobs['msa_name'].apply(lambda x: x.replace(\" NECTA\",\"\"))\n",
    "\n",
    "# Keep only december months\n",
    "new_jobs = jobs[jobs['month']=='December'].reset_index(drop=True)\n",
    "\n",
    "# Get earliest year\n",
    "earliest_year = new_jobs['year'].min()\n",
    "\n",
    "# Get latest year\n",
    "latest_year = new_jobs['year'].max()\n",
    "\n",
    "# Only keep certain columns\n",
    "new_jobs = new_jobs[['msa_name','year','value']]\n",
    "\n",
    "# Rename column\n",
    "new_jobs.rename(columns={'value':f'jobs'}, inplace=True)\n",
    "\n",
    "# Stack and unstack\n",
    "new_jobs = new_jobs.set_index(['msa_name','year'])\n",
    "new_jobs = new_jobs.unstack('year')\n",
    "\n",
    "# Reset index\n",
    "new_jobs = new_jobs.reset_index()\n",
    "\n",
    "# Rename jobs columns\n",
    "new_jobs.columns = ['msa_name'] + [\n",
    "    f'{i}_jobs' for i in range(earliest_year, latest_year + 1)]\n",
    "\n",
    "# Read in total units and rename columns\n",
    "total_units = pd.read_csv(\n",
    "    \"datasets/cleaned_census_api_files/msa_data/total_units_msa.csv\")\n",
    "for i in range(earliest_year, latest_year + 1):\n",
    "    total_units.rename(columns={f\"{i}\":f\"{i}_units\"}, inplace=True)\n",
    "    \n",
    "# Merge data\n",
    "jobs_per_unit = new_jobs.merge(\n",
    "    total_units, how='inner', \n",
    "    on=['msa_name'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(earliest_year, latest_year + 1):\n",
    "    jobs_per_unit[f'{i}'] = jobs_per_unit[f\"{i}_jobs\"]/jobs_per_unit[f\"{i}_units\"]\n",
    "        \n",
    "# Only keep main columns\n",
    "jobs_per_unit = jobs_per_unit[['msa_name','msa_code'] +\n",
    "    [f'{i}' for i in range(earliest_year, latest_year + 1)]]\n",
    "\n",
    "# Save dataset\n",
    "jobs_per_unit.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/msa_data/jobs_per_unit_msa.csv\", \n",
    "    index=False)\n",
    "\n",
    "jobs_per_unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d89fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f9c9e9",
   "metadata": {},
   "source": [
    "## Get data at the City Level (at the ACS 5-Year level)\n",
    "\n",
    "1. Population (B01003_001E)\n",
    "2. Median Income\n",
    "3. Median Unit Price\n",
    "4. Median Rent\n",
    "5. Total Units\n",
    "6. Percent Renter Occupied\n",
    "7. Total Employed (B23025_004E)\n",
    "\n",
    "Create Manually:\n",
    "1. Rent-to-Price Ratio\n",
    "2. People-per-Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define end year\n",
    "begin_year = 2011\n",
    "end_year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebf421",
   "metadata": {},
   "source": [
    "### Get Population (City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196488f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "population_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B01001_001E\",\n",
    "    census_code_meaning=\"population_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "population_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd9e93b",
   "metadata": {},
   "source": [
    "### Get Median Income (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e353cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_income_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B19013_001E\",\n",
    "    census_code_meaning=\"median_income_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "median_income_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bd918",
   "metadata": {},
   "source": [
    "### Get Median Price (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca33ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_price_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25077_001E\",\n",
    "    census_code_meaning=\"median_price_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "median_price_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825c49c",
   "metadata": {},
   "source": [
    "### Get Median Rent (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45c127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_rent_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25058_001E\",\n",
    "    census_code_meaning=\"median_rent_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "median_rent_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4a964",
   "metadata": {},
   "source": [
    "### Get Total Units (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b03bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_units_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25001_001E\",\n",
    "    census_code_meaning=\"total_units_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_units_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8082d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37f11920",
   "metadata": {},
   "source": [
    "## Get Percent Renter Occupied (city)\n",
    "\n",
    "1. First we must get Total Occupied Units (B25002_002E)\n",
    "2. Then we must get Renter Occupied Units (B25003_003E)\n",
    "\n",
    "3. Then we must manually divide Renters by Occupied units to get Percent Renter Occupied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd1ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_occupied_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25002_002E\",\n",
    "    census_code_meaning=\"total_occupied_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_occupied_city\n",
    "\n",
    "total_renter_occupied_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25003_003E\",\n",
    "    census_code_meaning=\"total_renter_occupied_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_renter_occupied_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34ba5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Manually get Percent Renter Occupied\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    total_occupied_city.rename(columns={f\"{i}\":f\"{i}_total_occupied\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    total_renter_occupied_city.rename(columns={f\"{i}\":f\"{i}_renter_occupied\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "percent_renter_city = total_occupied_city.merge(\n",
    "    total_renter_occupied_city, how='inner', \n",
    "    on=['name','geo_id'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    percent_renter_city[f'{i}'] = percent_renter_city[f\"{i}_renter_occupied\"]/percent_renter_city[f\"{i}_total_occupied\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    percent_renter_city.drop(columns=[\n",
    "        f'{i}_renter_occupied',f'{i}_total_occupied'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "percent_renter_city.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/city_data/percent_renter_occupied_city.csv\", \n",
    "    index=False)\n",
    "\n",
    "percent_renter_city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652570a",
   "metadata": {},
   "source": [
    "### Get Total Employed (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f4d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_employed_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B23025_004E\",\n",
    "    census_code_meaning=\"total_employed_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_employed_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead5cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2911ff2f",
   "metadata": {},
   "source": [
    "### Manually Create Rent-to-Price Ratio (city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc603460",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually get Rent to Price Ratio\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    median_rent_city.rename(columns={f\"{i}\":f\"{i}_rent\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    median_price_city.rename(columns={f\"{i}\":f\"{i}_price\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "rent_price_ratio_city = median_rent_city.merge(\n",
    "    median_price_city, how='inner', \n",
    "    on=['name','geo_id'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    rent_price_ratio_city[f'{i}'] = rent_price_ratio_city[f\"{i}_rent\"]/rent_price_ratio_city[f\"{i}_price\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    rent_price_ratio_city.drop(columns=[\n",
    "        f'{i}_rent',f'{i}_price'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "rent_price_ratio_city.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/city_data/rent_price_ratio_city.csv\", \n",
    "    index=False)\n",
    "\n",
    "rent_price_ratio_city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f994059",
   "metadata": {},
   "source": [
    "### Manually Create People-per-Units (city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f3a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually get People per Units\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    population_city.rename(columns={f\"{i}\":f\"{i}_population\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    total_units_city.rename(columns={f\"{i}\":f\"{i}_units\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "people_per_unit_city = population_city.merge(\n",
    "    total_units_city, how='inner', \n",
    "    on=['name','geo_id'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    people_per_unit_city[f'{i}'] = people_per_unit_city[f\"{i}_population\"]/people_per_unit_city[f\"{i}_units\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    people_per_unit_city.drop(columns=[\n",
    "        f'{i}_population',f'{i}_units'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "people_per_unit_city.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/city_data/people_per_unit_city.csv\", \n",
    "    index=False)\n",
    "\n",
    "people_per_unit_city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308db23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05769f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb41e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9747c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb183016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing_supply_and_demand",
   "language": "python",
   "name": "housing_supply_and_demand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
