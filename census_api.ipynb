{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabaacb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Suppress unnecessary Shapely warning\n",
    "warnings.filterwarnings('ignore',\n",
    "                        '.*Shapely GEOS version.*')\n",
    "\n",
    "from aiohttp import ClientSession\n",
    "from requests import request, Session\n",
    "from itertools import product, repeat\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "from threading import Thread\n",
    "import time\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import shapely\n",
    "import pygeos\n",
    "from functools import reduce\n",
    "from pandas.plotting import lag_plot\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import copy\n",
    "import math\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from multiprocess import Process, Pool\n",
    "\n",
    "# All helper functions are in this module:\n",
    "from helper_functions.census_functions import *\n",
    "\n",
    "# Set up Pandas defaults\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37101a2b",
   "metadata": {},
   "source": [
    "## Get Census Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2d08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test getting census key\n",
    "print(\"Census key:\", census_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30435e3",
   "metadata": {},
   "source": [
    "### Create the directories for file-saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folder(\"datasets/cleaned_census_api_files/\")\n",
    "create_folder(\"datasets/cleaned_census_api_files/graphable/\")\n",
    "create_folder(\"datasets/cleaned_census_api_files/raw/\")\n",
    "create_folder(\"datasets/cleaned_census_api_files/standardized/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d596b",
   "metadata": {},
   "source": [
    "## Following Tutorial Below\n",
    "Referencing [this](https://www.youtube.com/watch?v=LW-M_UC0VTE) tutorial.\n",
    "\n",
    "Here is the [Census API](https://www.census.gov/data/developers/data-sets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea3874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f65e2a0",
   "metadata": {},
   "source": [
    "## Get Population at the Tract Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a37950",
   "metadata": {},
   "source": [
    "### Get Population by block group for 2013-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b707a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Start list\n",
    "df_list = []\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Start session\n",
    "session = Session()\n",
    "\n",
    "# Define our API variable\n",
    "# It's within a dictionary because some variables\n",
    "# can change names from year to year (but not all)\n",
    "census_code_dict = {\n",
    "    2013: 'B01003_001E',\n",
    "    2014: 'B01003_001E',\n",
    "    2015: 'B01003_001E', # No change in code number this year\n",
    "    2016: 'B01003_001E',\n",
    "    2017: 'B01003_001E',\n",
    "    2018: 'B01003_001E',\n",
    "    2019: 'B01003_001E',\n",
    "    2020: 'B01003_001E',\n",
    "    2021: 'B01003_001E'\n",
    "}\n",
    "\n",
    "census_code_meaning='population_blocks'\n",
    "\n",
    "# Run the API call\n",
    "asyncio.run(url_to_dataframe_async_owners(2013, 2021, \n",
    "                                          fifty_states_list=fifty_states_list,\n",
    "                                          census_code_dict=census_code_dict,\n",
    "                                          df_list=df_list,\n",
    "                                          census_code_meaning=census_code_meaning,\n",
    "                                         get_blocks=True))\n",
    "\n",
    "# Get merged dataframe\n",
    "pop_by_blocks_raw = final_data_prep(df_list, census_code_meaning, blocks=True)\n",
    "pop_pre_st = merge_with_crosswalk(pop_by_blocks_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataframe\n",
    "pop_by_blocks_raw = pd.read_csv(\n",
    "    \"datasets/cleaned_census_api_files/raw/population_blocks_raw.csv\",\n",
    "    encoding='utf-8',\n",
    "    dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "          'tract':str, 'block group':str, 'block':str})\n",
    "pop_pre_st = merge_with_crosswalk(pop_by_blocks_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac0394",
   "metadata": {},
   "source": [
    "#### Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7843515",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This can and should be assigned to cloud parrallelization.\n",
    "# The good thing is this function only needs to run once.\n",
    "year_end = 2021\n",
    "pop_dictionary = {}\n",
    "array2 = pop_pre_st['BG20'].unique()\n",
    "\n",
    "# Run the standardization function\n",
    "[block_standardize(\n",
    "    x, pop_dict=pop_dictionary, og_df=pop_pre_st, year_end=year_end) for x in array2]\n",
    "\n",
    "saved_pop_dictionary = pop_dictionary.copy()\n",
    "\n",
    "pop_standardized_df_1 = (pd.DataFrame.from_dict(saved_pop_dictionary, \n",
    "                       orient='index', \n",
    "                       columns=[str(i) for i in range(2013, year_end + 1)])\n",
    "                       .reset_index()\n",
    "                       .rename(columns={'index':'geoid_block'})\n",
    "                      )\n",
    "\n",
    "pop_standardized_df_1.to_csv('datasets/cleaned_census_api_files/raw/population_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c4ec03",
   "metadata": {},
   "source": [
    "### Final dataframe clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d527fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_standardized_df_1 = pd.read_csv('datasets/cleaned_census_api_files/raw/population_standardized_raw.csv',\n",
    "                                  encoding='utf-8',\n",
    "                                 dtype={'geoid_block':str})\n",
    "\n",
    "# Run statistics function to get ratio and z-score\n",
    "pop_standardized_df_1 = get_statistics(\n",
    "    pop_standardized_df_1, begin_year=2013, end_year=2021)\n",
    "\n",
    "# Add columns for state,county, and tract, and make sums for census tracts\n",
    "pop_standardized_df_2 = specify_geographies(pop_standardized_df_1, 2013, 2021)\n",
    "display(pop_standardized_df_2.head(1))\n",
    "\n",
    "pop_standardized_df_2.to_csv('datasets/cleaned_census_api_files/standardized/population_standardized.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)\n",
    "\n",
    "# Plot zscores to check for anomalies\n",
    "plot_zscores(pop_standardized_df_2['z_score'], 'Population')\n",
    "\n",
    "# Create the shapefiles for block groups and tracts\n",
    "pop_tract_geo = create_and_save_geo_files(dataframe=pop_standardized_df_2, \n",
    "                                          name='population',\n",
    "                                          begin_year=2013, \n",
    "                                          end_year=2021)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a300f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9451dc90",
   "metadata": {},
   "source": [
    "### Group Tracts By City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef11f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Use the below function and incorporate it into the main\n",
    "##### cencus helper functions. \n",
    "\n",
    "def group_tracts_by_city(tract_gdf, city_name, state_name):\n",
    "    \"\"\"\n",
    "    Group tracts by a given city and save them as\n",
    "    an individual dataframes.\n",
    "    \n",
    "    Parameters:\n",
    "        tract_gdf (GeoDataFrame): The geodataframe\n",
    "            you want to split by city.\n",
    "        city_name (str): Name of city.\n",
    "        state_name (str): Name of state.\n",
    "    \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the city shapefile\n",
    "    city_boundaries = gp.read_file(\n",
    "        \"datasets/census_original_files/cities_2020/all_cities_2020/all_tracts_2020.shp\")\n",
    "    \n",
    "    # Filter by city name and state\n",
    "    \n",
    "    # Make copy\n",
    "    df = tract_gdf.copy()\n",
    "    \n",
    "    ### Below is an algorithm to only keep tracts\n",
    "    ### that are within 50% or more of a city's boundary\n",
    "    \n",
    "    # Step 1: Calculate area of each tract\n",
    "    df['tract_area'] = df.area\n",
    "    \n",
    "    # Step 2: Overlay the city boundaries over the tracts\n",
    "    df_2 = df.overlay(city_boundaries, how=\"intersect\")\n",
    "    \n",
    "    display(df_2)\n",
    "    \n",
    "    # Step 3: Calculate new areas\n",
    "    df_2['area_']\n",
    "    \n",
    "group_tracts_by_city(pop_tract_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6972825",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_tract_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83614fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Temporary code - can be deleted once file is created\n",
    "\n",
    "# Goal: Create csv that matches states to FIPS codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded2cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279dd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8887567",
   "metadata": {},
   "source": [
    "End of standardizing and merging population\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02513d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a99c419",
   "metadata": {},
   "source": [
    "## Median Gross Rent\n",
    "\n",
    "Estimated Median of bin values = ùëô + (ùëõ/2 ‚àí ùêπ)/ùëì ‚ãÖ ùë§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5a880",
   "metadata": {},
   "source": [
    "#### Below is their \"Median Value.\" Once we standardize, compare the values to this table below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6208082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Start list\n",
    "# df_list = []\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# # Start session\n",
    "# session = Session()\n",
    "\n",
    "# # Define our API variable\n",
    "# # It's within a dictionary because some variables\n",
    "# # can change names from year to year (but not all)\n",
    "# census_code_dict = {\n",
    "#     2013: 'B25064_001E',\n",
    "#     2014: 'B25064_001E',\n",
    "#     2015: 'B25064_001E', # No change in code number this year\n",
    "#     2016: 'B25064_001E',\n",
    "#     2017: 'B25064_001E',\n",
    "#     2018: 'B25064_001E',\n",
    "#     2019: 'B25064_001E',\n",
    "#     2020: 'B25064_001E',\n",
    "#     2021: 'B25064_001E'\n",
    "# }\n",
    "\n",
    "# census_code_meaning='median_rent_2013_2021_blocks'\n",
    "\n",
    "# # Run the API call\n",
    "# asyncio.run(url_to_dataframe_async_owners(2013, 2021, \n",
    "#                                           fifty_states_list,\n",
    "#                                           census_code_dict,\n",
    "#                                           df_list=df_list,\n",
    "#                                           census_code_meaning=census_code_meaning,\n",
    "#                                          get_blocks=True,\n",
    "#                                          ))\n",
    "\n",
    "# # Get merged dataframe\n",
    "# median_rent_raw = final_data_prep(df_list, census_code_meaning, blocks=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9fcd48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_rent_raw = pd.read_csv('datasets/cleaned_census_api_files/raw/median_rent_2013_2021_blocks_raw.csv',\n",
    "                                   encoding='utf-8',\n",
    "                                   dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "                                          'tract':str, 'block group':str, 'block':str})\n",
    "median_rent_raw['block'] = median_rent_raw['geo_id'].apply(lambda x: str(x)[-12:])\n",
    "\n",
    "spot_check(median_rent_raw, 2013, 2021)\n",
    "\n",
    "median_rent_raw.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17166bc5",
   "metadata": {},
   "source": [
    "#### Get Gross Rent for each category, then combine them! Try to get all codes for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Gross Rent Code for each year\n",
    "rent_code_list = []\n",
    "for i in range(3, 27):\n",
    "    if i < 10:\n",
    "        i = '0' + str(i)\n",
    "    rent_code_list.append(f'B25063_0{i}E')\n",
    "    \n",
    "rent_code_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f328b3e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Start list\n",
    "# df_list = []\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# # Start session\n",
    "# session = Session()\n",
    "\n",
    "# # Define our API variable\n",
    "# # It's within a dictionary because some variables\n",
    "# # can change names from year to year (but not all)\n",
    "# rent_code_list = []\n",
    "# for i in range(3, 27):\n",
    "#     if i < 10:\n",
    "#         i = '0' + str(i)\n",
    "#     rent_code_list.append(f'B25063_0{i}E')\n",
    "    \n",
    "# census_code_dict = {\n",
    "#     2013: rent_code_list[:-3],\n",
    "#     2014: rent_code_list[:-3],\n",
    "#     2015: rent_code_list, \n",
    "#     2016: rent_code_list,\n",
    "#     2017: rent_code_list,\n",
    "#     2018: rent_code_list,\n",
    "#     2019: rent_code_list,\n",
    "#     2020: rent_code_list,\n",
    "#     2021: rent_code_list\n",
    "# }\n",
    "\n",
    "# code_name_dict = {\n",
    "#     'B25063_003E': 'rent_less_than_100',\n",
    "#     'B25063_004E': 'rent_100_to_149',\n",
    "#     'B25063_005E': 'rent_150_to_199',\n",
    "#     'B25063_006E': 'rent_200_to_249',\n",
    "#     'B25063_007E': 'rent_250_to_299',\n",
    "#     'B25063_008E': 'rent_300_to_349',\n",
    "#     'B25063_009E': 'rent_350_to_399',\n",
    "#     'B25063_010E': 'rent_400_to_449',\n",
    "#     'B25063_011E': 'rent_450_to_499',\n",
    "#     'B25063_012E': 'rent_500_to_549',\n",
    "#     'B25063_013E': 'rent_550_to_599',\n",
    "#     'B25063_014E': 'rent_600_to_649',\n",
    "#     'B25063_015E': 'rent_650_to_699',\n",
    "#     'B25063_016E': 'rent_700_to_749',\n",
    "#     'B25063_017E': 'rent_750_to_799',\n",
    "#     'B25063_018E': 'rent_800_to_899',\n",
    "#     'B25063_019E': 'rent_900_to_999',\n",
    "#     'B25063_020E': 'rent_1000_to_1249',\n",
    "#     'B25063_021E': 'rent_1250_to_1449',\n",
    "#     'B25063_022E': 'rent_1500_to_1999',\n",
    "#     'B25063_023E': 'rent_2000_to_2499',\n",
    "#     'B25063_024E': 'rent_2500_to_2999',\n",
    "#     'B25063_025E': 'rent_3000_to_3499',\n",
    "#     'B25063_026E': 'rent_3500_or_more',\n",
    "# }\n",
    "\n",
    "# census_code_meaning='rent_distribution_blocks'\n",
    "\n",
    "# # Run the API call\n",
    "# asyncio.run(url_to_dataframe_async_owners(2013, 2021, \n",
    "#                                           fifty_states_list,\n",
    "#                                           census_code_dict,\n",
    "#                                           df_list=df_list,\n",
    "#                                           census_code_meaning=census_code_meaning,\n",
    "#                                          get_blocks=True,\n",
    "#                                          multi_code=True,\n",
    "#                                          code_name_dict=code_name_dict\n",
    "#                                          ))\n",
    "\n",
    "# # Get merged dataframe\n",
    "# rent_distribution = final_data_prep(df_list, census_code_meaning, blocks=True)\n",
    "# rent_dist_pre_st = merge_with_crosswalk(rent_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf619a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom spot checking\n",
    "# print(\"How many states:\", len(rent_dist['state'].value_counts()), \"\\n\")\n",
    "\n",
    "# for code in code_name_dict:\n",
    "    \n",
    "#     name = code_name_dict[code]\n",
    "    \n",
    "#     print(f\"Values for {name}\")\n",
    "    \n",
    "#     if (name != 'rent_2500_to_2999') and (name != 'rent_3000_to_3499') and (name != 'rent_3500_or_more'):\n",
    "        \n",
    "#         # Check for null values\n",
    "#         for i in range(2013, 2021):\n",
    "#             print(f\"{name} Null values in {i}:\", rent_dist[rent_dist[f'{i}_{name}'].isnull()].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check for null values in multiple years\n",
    "#         for i in range(2013, 2020):\n",
    "#             print(f\"2020 and {i} {name} null values:\", rent_dist[(rent_dist[f'2020_{name}'].isnull()) & (rent_dist[f'{i}_{name}'].isnull())].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check stats\n",
    "#         for i in range(2013, 2021):\n",
    "#             print(f\"{name} Stats for year {i}:\\n\", rent_dist[f'{i}_{name}'].describe(), \"\\n\")\n",
    "            \n",
    "#     else:\n",
    "        \n",
    "#         # Check for null values\n",
    "#         for i in range(2015, 2021):\n",
    "#             print(f\"{name} Null values in {i}:\", rent_dist[rent_dist[f'{i}_{name}'].isnull()].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check for null values in multiple years\n",
    "#         for i in range(2015, 2020):\n",
    "#             print(f\"2020 and {i} {name} null values:\", rent_dist[(rent_dist[f'2020_{name}'].isnull()) & (rent_dist[f'{i}_{name}'].isnull())].shape[0])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#         # Check stats\n",
    "#         for i in range(2015, 2021):\n",
    "#             print(f\"{name} Stats for year {i}:\\n\", rent_dist[f'{i}_{name}'].describe(), \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_dist = pd.read_csv('datasets/cleaned_census_api_files/raw/rent_distribution_blocks_raw.csv',\n",
    "                        encoding='utf-8',\n",
    "                       dtype={'geo_id':str, 'state':str, 'county':str, \n",
    "                                          'tract':str, 'block group':str, 'block':str})\n",
    "rent_dist_pre_st = merge_with_crosswalk(rent_dist)\n",
    "rent_dist_pre_st.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d7d92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_standardize_medians_3(bg20_df,\n",
    "                            og_df,\n",
    "                            year_start,\n",
    "                            year_end,\n",
    "                            weight,\n",
    "                            code_name_dict_2013_2014=False,\n",
    "                            code_name_dict_2015_2021=False,\n",
    "                            code_name_dict_all=False):\n",
    "\n",
    "    \"\"\"\n",
    "    WARNING: This function alone takes a few seconds to complete\n",
    "    per block group, but to standard all 242,333 block groups\n",
    "    can take many, many hours to run.\n",
    "    It would be wise to run this function on any type of\n",
    "    parrallel processing, such as using Dask, or a GPU,\n",
    "    or parrallelized cloud computing, as there is no\n",
    "    serialization (the block groups can be standardized\n",
    "    in no particular order).\n",
    "    \n",
    "    This function standardizes all block group rows. It \n",
    "    should be called in a loop or vectorized if possible,\n",
    "    such as the example below. (Note, the example below\n",
    "    may not be the most efficient way to loop through\n",
    "    or vectorize the block groups.)\n",
    "    \n",
    "    ```\n",
    "    # Loop through all population block groups\n",
    "    # and standardize them\n",
    "    pop_dictionary = {}\n",
    "    array2 = pop_pre_st['BG20'].unique()\n",
    "    [block_standardize(\n",
    "            x, \n",
    "            pop_dict=pop_dictionary, \n",
    "            og_df=pop_pre_st) \n",
    "        for x in array2]\n",
    "    ```\n",
    "    \n",
    "    Parameters:\n",
    "        tuple (tuple): A tuple containing the below.\n",
    "            block (str): The block_group to group by.\n",
    "            og_df (DataFrame): The dataframe we are \n",
    "                standardizing from.\n",
    "            year_start (int): Which year to start from.\n",
    "            year_end (int): Which year to end from.\n",
    "            weight (str): Which weight to use (such as \n",
    "                'wt_pop' pr 'wt_hh').\n",
    "    \n",
    "    Returns:\n",
    "        None. However, it appends the standardized values\n",
    "            per block group to a pre-defined dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    block = bg20_df['BG20'].iloc[0]\n",
    "        \n",
    "    # Step 1: Get a dataframe grouped by BG20\n",
    "    bg20_df = bg20_df.drop_duplicates()\n",
    "    bg20_df = bg20_df.fillna(0)\n",
    "    filtered = og_df[og_df['block']==block].copy().drop_duplicates()\n",
    "    \n",
    "    # make sure the final dict is in the form of {block : dots}\n",
    "    return_array = np.array([])\n",
    "    \n",
    "    if code_name_dict_all == False:\n",
    "    \n",
    "        # Step 2: Loop through the code names that 2013 and 2014 are guaranteed to have\n",
    "        for code in code_name_dict_2013_2014:\n",
    "\n",
    "            rent_category = code_name_dict_2013_2014[code]\n",
    "            years_13_19 = [f\"{i}_{rent_category}\" for i in range(2013, 2020)]\n",
    "\n",
    "            # Step 3: Get dot product of 2013-2019 values with the target weight values values\n",
    "            array_13_19 = bg20_df[years_13_19].to_numpy().T\n",
    "            wt_array = bg20_df[weight].to_numpy()\n",
    "            dots = array_13_19.dot(wt_array)\n",
    "\n",
    "            # Step 4: Append standardized 2013-2019 and \n",
    "            # the block's 2020+ values to new dictionary\n",
    "            val_20s = filtered[[\n",
    "                f\"{i}_{rent_category}\" for i in \n",
    "                range(2020, year_end + 1)]].iloc[0].to_numpy()\n",
    "            \n",
    "            # If the 2020 value is 0, then all years\n",
    "            # before then should be 0 also\n",
    "            if val_20s[0] == 0:\n",
    "                dots = dots * 0\n",
    "\n",
    "            # val_20 = filtered[f'2020_{rent_category}'].iloc[0]\n",
    "            \n",
    "            # Finalize the append\n",
    "            dots = np.append(dots, val_20s)\n",
    "\n",
    "            # Save a copy of the array\n",
    "            set_dots = dots.copy()\n",
    "\n",
    "            # Update return_dictionary\n",
    "            return_array = np.append(return_array, set_dots)\n",
    "\n",
    "        # Step 2: Loop through the code names that 2013 and 2014 won't have\n",
    "        for code in code_name_dict_2015_2021:\n",
    "\n",
    "            rent_category = code_name_dict_2015_2021[code]\n",
    "            years_15_19 = [f\"{i}_{rent_category}\" for i in range(2015, 2020)]\n",
    "\n",
    "            # Step 3: Get dot product of 2015-2019 values with the target weight values values\n",
    "            array_15_19 = bg20_df[years_15_19].to_numpy().T\n",
    "            wt_array = bg20_df[weight].to_numpy()\n",
    "            dots = array_15_19.dot(wt_array)\n",
    "            \n",
    "            # Step 4: Append standardized 2013-2019 and \n",
    "            # the block's 2020+ values to new dictionary\n",
    "            val_20s = filtered[[\n",
    "                f\"{i}_{rent_category}\" for i in \n",
    "                range(2020, year_end + 1)]].iloc[0].to_numpy()\n",
    "            \n",
    "            # If the 2020 value is 0, then all years\n",
    "            # before then should be 0 also\n",
    "            if val_20s[0] == 0:\n",
    "                dots = dots * 0\n",
    "            \n",
    "            # Finalize the append\n",
    "            dots = np.append(dots, val_20s)\n",
    "\n",
    "            # Save a copy of the array\n",
    "            set_dots = dots.copy()\n",
    "\n",
    "            # Update return_dictionary\n",
    "            return_array = np.append(return_array, set_dots)\n",
    "            \n",
    "    else: # if code_name_dict_all exists\n",
    "        for code in code_name_dict_all:\n",
    "\n",
    "            rent_category = code_name_dict_all[code]\n",
    "            years_13_19 = [f\"{i}_{rent_category}\" for i in range(2013, 2020)]\n",
    "\n",
    "            # Step 3: Get dot product of 2010-2019 values with the target weight values values\n",
    "            array_13_19 = bg20_df[years_13_19].to_numpy().T\n",
    "            wt_array = bg20_df[weight].to_numpy()\n",
    "            dots = array_13_19.dot(wt_array)\n",
    "            \n",
    "            # Step 4: Append standardized 2013-2019 and \n",
    "            # the block's 2020+ values to new dictionary\n",
    "            val_20s = filtered[[\n",
    "                f\"{i}_{rent_category}\" for i in \n",
    "                range(2020, year_end + 1)]].iloc[0].to_numpy()\n",
    "            \n",
    "            # If the 2020 value is 0, then all years\n",
    "            # before then should be 0 also\n",
    "            if val_20s[0] == 0:\n",
    "                dots = dots * 0\n",
    "\n",
    "            # Finalize the append\n",
    "            dots = np.append(dots, val_20s)\n",
    "\n",
    "            # Save a copy of the array\n",
    "            set_dots = dots.copy()\n",
    "\n",
    "            # Update return_dictionary\n",
    "            return_array = np.append(return_array, set_dots)\n",
    "        \n",
    "    return {block : return_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b9a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using list comprehension\n",
    "\n",
    "begin_year = 2013\n",
    "end_year = 2021\n",
    "\n",
    "my_groups = rent_dist_pre_st.groupby('BG20')\n",
    "keys = list(my_groups.groups.keys())\n",
    "\n",
    "code_name_dict_2013_2014 = {\n",
    "    'B25063_003E': 'rent_less_than_100',\n",
    "    'B25063_004E': 'rent_100_to_149',\n",
    "    'B25063_005E': 'rent_150_to_199',\n",
    "    'B25063_006E': 'rent_200_to_249',\n",
    "    'B25063_007E': 'rent_250_to_299',\n",
    "    'B25063_008E': 'rent_300_to_349',\n",
    "    'B25063_009E': 'rent_350_to_399',\n",
    "    'B25063_010E': 'rent_400_to_449',\n",
    "    'B25063_011E': 'rent_450_to_499',\n",
    "    'B25063_012E': 'rent_500_to_549',\n",
    "    'B25063_013E': 'rent_550_to_599',\n",
    "    'B25063_014E': 'rent_600_to_649',\n",
    "    'B25063_015E': 'rent_650_to_699',\n",
    "    'B25063_016E': 'rent_700_to_749',\n",
    "    'B25063_017E': 'rent_750_to_799',\n",
    "    'B25063_018E': 'rent_800_to_899',\n",
    "    'B25063_019E': 'rent_900_to_999',\n",
    "    'B25063_020E': 'rent_1000_to_1249',\n",
    "    'B25063_021E': 'rent_1250_to_1449',\n",
    "    'B25063_022E': 'rent_1500_to_1999',\n",
    "    'B25063_023E': 'rent_2000_to_2499'\n",
    "}\n",
    "\n",
    "code_name_dict_2015_2021 = {\n",
    "    'B25063_024E': 'rent_2500_to_2999',\n",
    "    'B25063_025E': 'rent_3000_to_3499',\n",
    "    'B25063_026E': 'rent_3500_or_more'\n",
    "}\n",
    "\n",
    "dict2 = {}\n",
    "dict3 = [block_standardize_medians_3(my_groups.get_group(keys[i]), \n",
    "                                rent_dist_pre_st, \n",
    "                                begin_year, \n",
    "                                end_year, \n",
    "                                'wt_hh', \n",
    "                                code_name_dict_2013_2014=code_name_dict_2013_2014, \n",
    "                                code_name_dict_2015_2021=code_name_dict_2015_2021)\n",
    "        for i in range(len(keys))\n",
    "       ]\n",
    "\n",
    "\n",
    "for d in dict3:\n",
    "    dict2.update(d)\n",
    "\n",
    "column_list = []\n",
    "for code in code_name_dict_2013_2014:\n",
    "    for i in range(begin_year, end_year + 1):\n",
    "        column_list.append(f'{i}_{code_name_dict_2013_2014[code]}')\n",
    "for code in code_name_dict_2015_2021:\n",
    "    for i in range(begin_year, end_year + 1):\n",
    "        column_list.append(f'{i}_{code_name_dict_2015_2021[code]}')\n",
    "\n",
    "gross_rent_df = (pd.DataFrame.from_dict(dict2, \n",
    "                   orient='index', columns=column_list)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'index':'geoid_block'}))\n",
    "\n",
    "gross_rent_df.to_csv('datasets/cleaned_census_api_files/raw/gross_rent_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)\n",
    "\n",
    "gross_rent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d473ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_df.to_csv('datasets/cleaned_census_api_files/raw/gross_rent_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934415",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_df = pd.read_csv('datasets/cleaned_census_api_files/raw/gross_rent_standardized_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          dtype={'geoid_block':str})\n",
    "\n",
    "# Make geoid_block the index\n",
    "gross_rent_df.set_index('geoid_block', inplace=True)\n",
    "gross_rent_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67f790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088606c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dee35242",
   "metadata": {},
   "source": [
    "### Once I have the gross rents standardized, calculate the median value for each year using frequency tables\n",
    "\n",
    "Estimated Median of bin values = ùëô + (ùëõ/2 ‚àí ùêπ)/ùëì ‚ãÖ ùë§\n",
    "\n",
    "where ùëô is the lower border of the median group, ùêπ is the cumulative frequency up to the median group, ùëì is the frequency of the median group, ùë§ is the width of the median group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29f08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEPS TO ESTIMATE MEDIAN VALUE\n",
    "def estimate_median(series, year, keyword):\n",
    "    \"\"\"\n",
    "    Estimate the median for a given year.\n",
    "    \"\"\"\n",
    "    s = series.copy()\n",
    "    year = str(year)\n",
    "#     print(series.name)\n",
    "    \n",
    "    # Gather all variables for the equation\n",
    "    non_zero_series = s[s != 0]\n",
    "    n = non_zero_series.sum()\n",
    "    \n",
    "    if len(non_zero_series) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Find median interval\n",
    "    median_n = n/2\n",
    "\n",
    "    series_dict = non_zero_series.to_dict()\n",
    "    key_list = list(series_dict.keys())\n",
    "    count = 0\n",
    "    interval = ''\n",
    "    interval_backup = None\n",
    "    i = 0\n",
    "    while i < len(key_list):\n",
    "        key = key_list[i]\n",
    "        if count < median_n:\n",
    "            interval = key\n",
    "            count += series_dict[key]\n",
    "            if count > median_n:\n",
    "                F = count - series_dict[key]\n",
    "        elif count == median_n:\n",
    "            F = count\n",
    "            interval_backup = key_list[i]\n",
    "            i = len(key_list)\n",
    "        else:\n",
    "            pass\n",
    "        i += 1\n",
    "        \n",
    "    f = series_dict[interval]\n",
    "        \n",
    "    # Get l, the lower bound\n",
    "    interval_bound = interval.replace(f'{year}_{keyword}_','')\n",
    "    l = int(re.sub(r'_to_\\d+|less_than_|_or_more','',interval_bound))\n",
    "    \n",
    "    # Get higher bound\n",
    "    h = int(re.sub(r'\\d+_to_|less_than_|_or_more','',interval_bound))\n",
    "\n",
    "    # Get width\n",
    "    w = h - l\n",
    "    \n",
    "    # Calculate almost_median\n",
    "    almost_median = (((n/2) - F)/f)*w\n",
    "    \n",
    "    # Check if there is no \"median interval\"\n",
    "    if (almost_median == 0) & (interval_backup is not None):\n",
    "        \n",
    "        # Get l, the lower bound\n",
    "        interval_higher_bound = interval_backup.replace(f'{year}_{keyword}_','')\n",
    "        l_higher = int(re.sub(r'_to_\\d+|less_than_|_or_more','',\n",
    "                              interval_higher_bound))\n",
    "\n",
    "        # Get higher bound\n",
    "        h_higher = int(re.sub(r'\\d+_to_|less_than_|_or_more','',interval_higher_bound))\n",
    "\n",
    "        # Calculate average of lower-lower bound and higher-higher bound\n",
    "        split_intervals_median = (l + h_higher)/2\n",
    "        \n",
    "        # This is our median\n",
    "        return split_intervals_median\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        # estimate median\n",
    "        estimated_median = l + almost_median\n",
    "\n",
    "        return estimated_median\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b4e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians = gross_rent_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357aee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Calculate gross rent for every year\n",
    "for i in range(2013, 2021):\n",
    "    columns_year = gross_rent_df.columns[gross_rent_df.columns.str.contains(str(i))]\n",
    "    gross_rent_medians[f'{i}_median'] = gross_rent_df[columns_year].apply(\n",
    "        lambda x: estimate_median(x, str(i), 'rent'),\n",
    "        axis=1\n",
    "    )\n",
    "gross_rent_medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c000484",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians.to_csv('datasets/cleaned_census_api_files/raw/gross_rent_medians_raw.csv',\n",
    "                          encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians = pd.read_csv('datasets/cleaned_census_api_files/raw/gross_rent_medians_raw.csv',\n",
    "                          encoding='utf-8',\n",
    "                          dtype={'geoid_block':str}\n",
    "                                )\n",
    "gross_rent_medians.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_medians = gross_rent_medians[['geoid_block','2013_median','2014_median','2015_median',\n",
    "                                        '2016_median','2017_median','2018_median',\n",
    "                                        '2019_median','2020_median']]\n",
    "gross_rent_medians.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41dce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loop that goes through each year backyards, \n",
    "# and linearly interpolate values between 0 values \n",
    "# (to show one consistent line on a grpah between two points spearated by \"0\")\n",
    "def linearly_interpolate(dataframe, \n",
    "                         grouping='block'):\n",
    "    \"\"\"Linearly interpolate NaN values.\"\"\"\n",
    "    df = copy.deepcopy(dataframe)\n",
    "    df = df.replace(0, np.nan)\n",
    "    df = df.set_index(f'geoid_{grouping}')\n",
    "    df = df.interpolate(axis=1).reset_index()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e582cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_interpolated = linearly_interpolate(gross_rent_medians)\n",
    "median_rent_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286212d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### Now get the median tract values\n",
    "def get_tract_median_values(dataframe):\n",
    "    \"Sum blocks for tracts then calculate each year's median.\"\n",
    "    \n",
    "    df = copy.deepcopy(dataframe)\n",
    "    if 'geoid_block' not in df.columns:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    df['geoid_tract'] = df['geoid_block'].apply(lambda x: str(x)[:-1])\n",
    "    df['state'] = df['geoid_block'].apply(lambda x: str(x)[0:2])\n",
    "    df['county'] = df['geoid_block'].apply(lambda x: str(x)[2:5])\n",
    "    \n",
    "    # Calculate gross rent for every year\n",
    "    for i in range(2013, 2021):\n",
    "        str_year = str(i)\n",
    "        columns_year = df.columns[df.columns.str.contains(str_year)]\n",
    "        for col in columns_year:\n",
    "            main_name = col.replace(f'{i}_rent_','')\n",
    "            df[f'{i}_tract_rent_{main_name}'] = df.groupby('geoid_tract')[f'{col}'].transform('sum')\n",
    "        tracts_year = df.columns[df.columns.str.contains(f'{str_year}_tract')]\n",
    "        df[f'{i}_tract_median'] = df[tracts_year].apply(\n",
    "            lambda x: estimate_median(x, str(i), 'tract_rent'),\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "gross_rent_tract = get_tract_median_values(gross_rent_df)\n",
    "gross_rent_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74516d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gross_rent_tract_2 = gross_rent_tract[['geoid_tract',\n",
    "                                       '2013_tract_median','2014_tract_median','2015_tract_median',\n",
    "                                        '2016_tract_median','2017_tract_median','2018_tract_median',\n",
    "                                        '2019_tract_median','2020_tract_median']].drop_duplicates()\n",
    "gross_rent_tract_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6737d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_tract_rent_interpolated = linearly_interpolate(gross_rent_tract_2, grouping='tract')\n",
    "median_tract_rent_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_interpolated['geoid_tract'] = median_rent_interpolated['geoid_block'].apply(\n",
    "    lambda x: str(x)[:-1])\n",
    "\n",
    "median_rent_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8382e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all = pd.merge(median_rent_interpolated,\n",
    "                           median_tract_rent_interpolated,\n",
    "                           left_on=\"geoid_tract\",\n",
    "                           right_on=\"geoid_tract\",\n",
    "                           how='inner')\n",
    "\n",
    "median_rent_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2013, 2021):\n",
    "    median_rent_all.rename(columns={f'{year}_median': f'{year}_block_median'}, inplace=True)\n",
    "    \n",
    "median_rent_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9be15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all['state'] = median_rent_all['geoid_block'].apply(lambda x: str(x)[0:2])\n",
    "median_rent_all['county'] = median_rent_all['geoid_block'].apply(lambda x: str(x)[2:5])\n",
    "median_rent_all['tract'] = median_rent_all['geoid_block'].apply(lambda x: str(x)[5:11])\n",
    "\n",
    "median_rent_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85cd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all.to_csv('datasets/cleaned_census_api_files/standardized/median_rent_standardized.csv',\n",
    "                       encoding='utf-8',\n",
    "                       index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_all = pd.read_csv('datasets/cleaned_census_api_files/standardized/median_rent_standardized.csv',\n",
    "                               encoding='utf-8',\n",
    "                             dtype={'geoid_block':str, 'geoid_tract':str})\n",
    "\n",
    "median_rent_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb470ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Once I have the interpolated median tract values, merge with block level,\n",
    "# Save, then run create_and_save_geo_files() function on it\n",
    "\n",
    "# Create the shapefiles for block groups and tracts\n",
    "median_rent_block_geo, median_rent_tract_geo = create_and_save_geo_files(dataframe=median_rent_all, \n",
    "                                                          name='median_rent',\n",
    "                                                          keyword='median',\n",
    "                                                          begin_year=2013, \n",
    "                                                          end_year=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_rent_block_geo\n",
    "median_rent_tract_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f6e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc6a9cb5",
   "metadata": {},
   "source": [
    "### End of getting data at the Tract level\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dfeacc",
   "metadata": {},
   "source": [
    "# Get data at the MSA level\n",
    "\n",
    "We will get the following:\n",
    "1. Median Income\n",
    "2. Median Unit Price\n",
    "3. Median Rent\n",
    "\n",
    "using the ACS 1-Year survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c103c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set end year for all MSAs\n",
    "end_year=2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0268c",
   "metadata": {},
   "source": [
    "### Get Median Income at the MSA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331b095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_income_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B19013_001E\",\n",
    "    census_code_meaning=\"median_income_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "median_income_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a2fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4902f25",
   "metadata": {},
   "source": [
    "### Get Median Unit Value at the MSA Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff1dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_price_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B25077_001E\",\n",
    "    census_code_meaning=\"median_price_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "median_price_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d0f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e59a5c9",
   "metadata": {},
   "source": [
    "### Get Median Rent at the MSA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a878dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_rent_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B25058_001E\",\n",
    "    census_code_meaning=\"median_rent_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "median_rent_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49140d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "812a5a48",
   "metadata": {},
   "source": [
    "### Get Total Units at the MSA level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f80a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_units_msa = download_and_format_msa_census_data(\n",
    "    census_code=\"B25001_001E\",\n",
    "    census_code_meaning=\"total_units_msa\",\n",
    "    end_year=end_year\n",
    ")\n",
    "total_units_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a2550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da670033",
   "metadata": {},
   "source": [
    "### Create Rent-to-Price Ratio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388e383",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "for i in range(2010, end_year + 1):\n",
    "    median_rent_msa.rename(columns={f\"{i}\":f\"{i}_rent\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(2010, end_year + 1):\n",
    "    median_price_msa.rename(columns={f\"{i}\":f\"{i}_price\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "rent_to_price = median_rent_msa.merge(\n",
    "    median_price_msa, how='inner', \n",
    "    on=['msa_code','msa_name'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(2010, end_year + 1):\n",
    "    rent_to_price[f'{i}'] = rent_to_price[f\"{i}_rent\"]/rent_to_price[f\"{i}_price\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    rent_to_price.drop(columns=[f'{i}_rent',f'{i}_price'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "rent_to_price.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/msa_data/rent_price_ratio_msa.csv\", \n",
    "    index=False)\n",
    "\n",
    "rent_to_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10444a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c548b35",
   "metadata": {},
   "source": [
    "### Create Jobs per Unit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b69fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in jobs\n",
    "jobs = pd.read_csv('datasets/bls/raw/most_recent_bls_data.csv',\n",
    "                   dtype={'msa_code':str, 'state_code':str})\n",
    "\n",
    "# Make sure the date column is in datetime format\n",
    "jobs['date'] = pd.to_datetime(jobs['date'])\n",
    "\n",
    "# Replace NECTA Division\n",
    "jobs['msa_name'] = jobs['msa_name'].apply(lambda x: x.replace(\" NECTA Division\",\"\"))\n",
    "jobs['msa_name'] = jobs['msa_name'].apply(lambda x: x.replace(\" NECTA\",\"\"))\n",
    "\n",
    "# Keep only december months\n",
    "new_jobs = jobs[jobs['month']=='December'].reset_index(drop=True)\n",
    "\n",
    "# Get earliest year\n",
    "earliest_year = new_jobs['year'].min()\n",
    "\n",
    "# Get latest year\n",
    "latest_year = new_jobs['year'].max()\n",
    "\n",
    "# Only keep certain columns\n",
    "new_jobs = new_jobs[['msa_name','year','value']]\n",
    "\n",
    "# Rename column\n",
    "new_jobs.rename(columns={'value':f'jobs'}, inplace=True)\n",
    "\n",
    "# Stack and unstack\n",
    "new_jobs = new_jobs.set_index(['msa_name','year'])\n",
    "new_jobs = new_jobs.unstack('year')\n",
    "\n",
    "# Reset index\n",
    "new_jobs = new_jobs.reset_index()\n",
    "\n",
    "# Rename jobs columns\n",
    "new_jobs.columns = ['msa_name'] + [\n",
    "    f'{i}_jobs' for i in range(earliest_year, latest_year + 1)]\n",
    "\n",
    "# Read in total units and rename columns\n",
    "total_units = pd.read_csv(\n",
    "    \"datasets/cleaned_census_api_files/msa_data/total_units_msa.csv\")\n",
    "for i in range(earliest_year, latest_year + 1):\n",
    "    total_units.rename(columns={f\"{i}\":f\"{i}_units\"}, inplace=True)\n",
    "    \n",
    "# Merge data\n",
    "jobs_per_unit = new_jobs.merge(\n",
    "    total_units, how='inner', \n",
    "    on=['msa_name'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(earliest_year, latest_year + 1):\n",
    "    jobs_per_unit[f'{i}'] = jobs_per_unit[f\"{i}_jobs\"]/jobs_per_unit[f\"{i}_units\"]\n",
    "        \n",
    "# Only keep main columns\n",
    "jobs_per_unit = jobs_per_unit[['msa_name','msa_code'] +\n",
    "    [f'{i}' for i in range(earliest_year, latest_year + 1)]]\n",
    "\n",
    "# Save dataset\n",
    "jobs_per_unit.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/msa_data/jobs_per_unit_msa.csv\", \n",
    "    index=False)\n",
    "\n",
    "jobs_per_unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d89fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84f9c9e9",
   "metadata": {},
   "source": [
    "## Get data at the City Level (at the ACS 5-Year level)\n",
    "\n",
    "1. Population (B01003_001E)\n",
    "2. Median Income\n",
    "3. Median Unit Price\n",
    "4. Median Rent\n",
    "5. Total Units\n",
    "6. Percent Renter Occupied\n",
    "7. Total Employed (B23025_004E)\n",
    "\n",
    "Create Manually:\n",
    "1. Rent-to-Price Ratio\n",
    "2. People-per-Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define end year\n",
    "begin_year = 2011\n",
    "end_year = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebf421",
   "metadata": {},
   "source": [
    "### Get Population (City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196488f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "population_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B01001_001E\",\n",
    "    census_code_meaning=\"population_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "population_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818ce70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd9e93b",
   "metadata": {},
   "source": [
    "### Get Median Income (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e353cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_income_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B19013_001E\",\n",
    "    census_code_meaning=\"median_income_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "median_income_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bd918",
   "metadata": {},
   "source": [
    "### Get Median Price (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca33ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_price_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25077_001E\",\n",
    "    census_code_meaning=\"median_price_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "median_price_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8825c49c",
   "metadata": {},
   "source": [
    "### Get Median Rent (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45c127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "median_rent_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25058_001E\",\n",
    "    census_code_meaning=\"median_rent_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "median_rent_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de4a964",
   "metadata": {},
   "source": [
    "### Get Total Units (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b03bde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_units_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25001_001E\",\n",
    "    census_code_meaning=\"total_units_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_units_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8082d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37f11920",
   "metadata": {},
   "source": [
    "## Get Percent Renter Occupied (city)\n",
    "\n",
    "1. First we must get Total Occupied Units (B25002_002E)\n",
    "2. Then we must get Renter Occupied Units (B25003_003E)\n",
    "\n",
    "3. Then we must manually divide Renters by Occupied units to get Percent Renter Occupied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd1ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_occupied_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25002_002E\",\n",
    "    census_code_meaning=\"total_occupied_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_occupied_city\n",
    "\n",
    "total_renter_occupied_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B25003_003E\",\n",
    "    census_code_meaning=\"total_renter_occupied_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_renter_occupied_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34ba5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Manually get Percent Renter Occupied\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    total_occupied_city.rename(columns={f\"{i}\":f\"{i}_total_occupied\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    total_renter_occupied_city.rename(columns={f\"{i}\":f\"{i}_renter_occupied\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "percent_renter_city = total_occupied_city.merge(\n",
    "    total_renter_occupied_city, how='inner', \n",
    "    on=['name','geo_id'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    percent_renter_city[f'{i}'] = percent_renter_city[f\"{i}_renter_occupied\"]/percent_renter_city[f\"{i}_total_occupied\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    percent_renter_city.drop(columns=[\n",
    "        f'{i}_renter_occupied',f'{i}_total_occupied'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "percent_renter_city.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/city_data/percent_renter_occupied_city.csv\", \n",
    "    index=False)\n",
    "\n",
    "percent_renter_city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652570a",
   "metadata": {},
   "source": [
    "### Get Total Employed (city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f4d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the API download function\n",
    "total_employed_city = download_and_format_msa_census_data(\n",
    "    census_code=\"B23025_004E\",\n",
    "    census_code_meaning=\"total_employed_city\",\n",
    "    begin_year=begin_year,\n",
    "    end_year=end_year,\n",
    "    format_msa=False,\n",
    "    format_city=True\n",
    ")\n",
    "total_employed_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead5cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2911ff2f",
   "metadata": {},
   "source": [
    "### Manually Create Rent-to-Price Ratio (city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc603460",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually get Rent to Price Ratio\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    median_rent_city.rename(columns={f\"{i}\":f\"{i}_rent\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    median_price_city.rename(columns={f\"{i}\":f\"{i}_price\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "rent_price_ratio_city = median_rent_city.merge(\n",
    "    median_price_city, how='inner', \n",
    "    on=['name','geo_id'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    rent_price_ratio_city[f'{i}'] = rent_price_ratio_city[f\"{i}_rent\"]/rent_price_ratio_city[f\"{i}_price\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    rent_price_ratio_city.drop(columns=[\n",
    "        f'{i}_rent',f'{i}_price'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "rent_price_ratio_city.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/city_data/rent_price_ratio_city.csv\", \n",
    "    index=False)\n",
    "\n",
    "rent_price_ratio_city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f994059",
   "metadata": {},
   "source": [
    "### Manually Create People-per-Units (city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f3a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manually get People per Units\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    population_city.rename(columns={f\"{i}\":f\"{i}_population\"}, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    total_units_city.rename(columns={f\"{i}\":f\"{i}_units\"}, inplace=True)\n",
    "\n",
    "# Merge price data\n",
    "people_per_unit_city = population_city.merge(\n",
    "    total_units_city, how='inner', \n",
    "    on=['name','geo_id'])\n",
    "\n",
    "# Loop through columns and divide rent by price per year\n",
    "for i in range(begin_year, end_year + 1):\n",
    "    people_per_unit_city[f'{i}'] = people_per_unit_city[f\"{i}_population\"]/people_per_unit_city[f\"{i}_units\"]\n",
    "    \n",
    "    # Drop rent and price columns\n",
    "    people_per_unit_city.drop(columns=[\n",
    "        f'{i}_population',f'{i}_units'], inplace=True)\n",
    "\n",
    "# Save dataset\n",
    "people_per_unit_city.to_csv(\n",
    "    \"datasets/cleaned_census_api_files/city_data/people_per_unit_city.csv\", \n",
    "    index=False)\n",
    "\n",
    "people_per_unit_city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308db23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05769f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb41e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9747c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb183016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing_supply_and_demand",
   "language": "python",
   "name": "housing_supply_and_demand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
